{"text": " Okay, let me take a look at the audience. I think we have most of them so I should probably get started. Okay, sounds good. Thanks Dr. Gannon. And I think Jared's already started recording. Okay. Welcome everyone. I'm so happy to see you all here at the I will be faculty seminar. And today I have the honor to introduce Dr. Robert Edgar, Dr. Robert Edgar has a Bachelor of Science in physics and a PhD in particle physics from University College London. He served as a CTO of IDBS APS in Copenhagen, from 1982 to 1988, where he designed and implemented a groundbreaking database server and application development environment. In 1988, Dr. Edgar founded parity software in San Francisco, where he served as CEO, chief architect and lead developer. He software development tools for computer telephony applications won numerous industrial awards and he grew the business to 30 employees and 10 million per year in sales before selling it to Intel in 1999. Dr. Edgar has things focused his attention on computational biology and bioinformatics, and it's best known for developing the widely used muscle and you search programs, which have been cited in thousands of published papers, his contributions to the field are significant and recognized with the night 2019 study reporting him as one of the top 0.01% of living scientists for the impact of his work today Dr. Thank you. Thank you very much. Pleasure to be here in Athens I think it's my first time out. But so today I'm going to talk about sequence alignment, and a little bit about the latest version of muscle, but I want to sort of draw some larger lessons about how people general generally use bioinformatics tools. How do I find like that. Okay, so I understand we have a variety of backgrounds here so some people may be more or less familiar with this kind of thing so I'm going to assume you basically know the idea of a sequence alignment. And here I'm going to focus on various polymerases, and you can sort of see here we have an alignment and gel view and you can sort of see by eyeball this looks very reasonable. I mean, you don't need muscle any any alignment, you can do it manually, it's pretty straightforward. And I'm focusing on various polymerase because right now with the pandemic. It's kind of a, it's very relevant it's relevant for virus discovery and I'm not going to talk about this today but I just wanted to motivate why I'm particularly interested in virus polymerases. So this was a really remarkable project that I was involved in still involved in it was started by an unemployed Canadian postdoc at the beginning of the pandemic with the goal of trying to understand where COVID-19 came from, and it attracted a sort of an all star team of volunteers scientists from all over the world who kind of put their time into this. And there's a happy ending to the story because Dr babian who was then unemployed is now an assistant professor in Toronto, and the sort of the headline of our paper last year was we increase the number of known RNA virus species by about an order of magnitude before we did this for about 10,000 species and now we know 130,000 and so this got me kind of interested in how can we align and classify all these new guys. And COVID, it is an RNA virus and you know this is sort of the background for why I'm using this example. So how do you actually make a sequence alignment. Well, under the hood, it's, it's important to understand that these algorithms are really using an X, a highly simplified model of evolution, I mean oversimplified really because you, we proteins are really complicated. So these are just some sort of very, I guess crude averages over how proteins behave because that's really the only way we know how to do it as a practical matter. And then there's a, the, the way that proteins evolve as you have these substitution scores which says, you know how likely it is for one residue to be replaced by another. And you have this very simple model of insertions and deletions which penalizes, adding gaps to the alignment. It's just really not that simple I mean Moses did not come down from a mountain and tell proteins to obey these laws so it's, it's just something to bear in mind that what's really going on here is something much more complicated and you should always be skeptical that the alignment is really correct or informative I mean sometimes it's obvious like that first example I showed, but you should always be kind of skeptical. So here, so this is that same alignment, which this is a bunch of Corona viruses and it's two regions from the same alignment. So the one I showed the top yeah that's that's convincing everyone would do it manually all programs are going to agree. And if you look at the other region there, I've shown at the bottom it's like well, how, I mean, really, how do we know, does the computer know. And the answer is no the computer doesn't know any more than we do because it's using these very simplified models and what it does the best it can but if you get, if you get this to two different programs, it's going to give you different results Well, how would you choose. So, this kind of raises. Sorry, excuse me. So, this raises the question well, when is an alignment correct or when is it even useful. And once you get in those more challenging regions like the bottom one I just showed that the answer is not necessarily that well defined, there's two main ways of thinking about it. One is that the letters you see in a given column should all come from the same ancestral letters so that's technically called residue homology. The other way you can say as well if you align the structures, the things that are in the same place in the structure should be in the same column. But what, unless the structures really line up very well, that's kind of ambiguous so you start to have the same kind of ambiguity as you have with the letters so even structure doesn't really provide you a definitive standard and the sort of a gray area where the structures diverge the less clear, it is what you're really trying to do. So, this alignment, it could be just flat out wrong, depending what you want to do. In particular, there are, there are some kinds of inferences like phylogenetic trees where it really is very clear that you need homologous residues in the same column but then some other applications, it might not be so, so clear it might be useful so there's some ambiguity in the alignment. And worst case, this could be really throwing you completely off track if you try to estimate a phylogenetic tree and you give it a region like this, you may just be getting complete nonsense. And another thing to keep in mind is that if you, if you sort of represent an alignment like this in a row and column matrix, you're assuming the sort of an implicit assumption that all of the mutations that have happened between the sequences are all mutations or maybe some short insertions and deletions, but there are many other types of mutation that can happen that you simply can't represent in a matrix like that. Well, there can be an inversion which is sort of more something you think about in DNA maybe. I mean, what's the most common short of the sort of the common. Well, what's the most common source of a short insertion, that's hard to say. And that's a short tandem duplication, the most common way that the new letter gets inserted into a protein is you get a little slippage when the, the gene is duplicated. So these are actually a very common source of mutation, then you've got translocations, and you've got this rather technical thing called the homoplasy and so when you've got distantly related proteins, and you have these more variable regions in the loops of the protein, you get insertions, deletions, substitutions, and eventually there's just no residue homology left. And so if the way you should really represent that in a multiple alignment is to have a ton of gaps, but, but alignment algorithms will never represent it that way. So I'm going to focus particularly on trees, because it's a very common application of an alignment, and it kind of illustrates the issues I want to talk about. So alignment in itself is not usually the end goal. So the questions you should be asking are not necessarily is alignment in itself, good or bad. The question is, is it good enough to answer the biological question that you're trying to answer. And here I'm going to take a concrete example, which is kind of relevant right now, if we're interested in the evolutionary history of COVID, we want to make phylogenetic trees for the coronavirus family. And it's kind of, it's the coronavirus divides quite clearly into four different groups which are called genera. There's just four, that's just kind of the convention in taxonomy. And so I went around the literature and I pulled some, some trees. So ABDG is alpha beta gamma delta here. And you can see that out of six trees I found in the literature, none of them agree with each other, but they all have very high confidence levels. So if you know about phylogenetic trees, the way that you estimate confidence is the same called a bootstrap value and it goes from zero to 100 or from zero to one depending what unit you use. You can see here, all these trees have high confidence, but they disagree with each other. So, at most, one of those trees can be right so something is going wrong here. So we need to go back and we'll check our assumptions here because the sort of conventional assumptions about how to do this is simply not working. And the answer here is that bootstrapping assumes the alignment is correct. So typically, you make a tree, you see the high bootstraps, you kind of think okay everything's working okay. But bootstraps is not a test of whether your alignment is good enough to make the tree, it assumes that the alignment is correct and then asks, is there enough information in the alignment to make the tree. But if there are systematic errors in the alignment, you have a problem. So, what can we do about this. Well, you know if you're a good biologist you know you're supposed to do replicates of your experiment you try the same experiment, repeat and see just start measuring errors and so on. And you can see we sort of got a model of how we might do this in the literature right here well these guys. Why did they get different trees well they chose a different alignment method and a different tree building software so maybe DeGroote used muscle and Raxomel, maybe Zhu used Maft and QuickTree. And they they came up with different answers so maybe what we should do is we should just like. Do all the try several different ways, ourselves, and see if they give consistent answers. Now people are people essentially never do that. And so, why not, then I think the answer to that is that people generally they've got some idea about well what's the best method because there's a benchmark test out there, or because their friend told them that's how they do it. And they think the friend is more expert than they are. So there's sort of this general perception that there's one way that's the best or shown to be the best or I'm just going to work with it. And there's sort of a concern that if you use some other method that's not quite as good as the best method, then well you discount the fact that that method disagrees, and you just trust the best one. So, I don't know, there's whatever the psychological sociological reason this is almost never done, but this example shows that maybe people should be doing this. So, this gives me sort of the motivation for the essentially new ideas that are in muscle five, which is, well, how can we do this. So if you remember back to the opening slides when we, when a computer makes an alignment. It's based on this very, very simple model where we have a substitution matrix, and typically a couple of lines. Excuse me. So if you remember back to the opening slides when we, when a computer makes an alignment. It's based on this very, very simple model where we have a substitution matrix and typically a couple of gap penalties. And you take the how do you set those parameters well you measure them on some benchmark and then you set the default values for those parameters, based on whatever comes out best on the benchmark. But if you think about it, they're kind of right round numbers and averaged over benchmark so should they really matter whether you use five or 5.1 or two or 1.9 for your gap penalties and the answer really, it shouldn't matter if it does, then you should start to be suspicious that your results are any good. So the idea is to do what I call perturbing parameters, so we introduced some small random variations for example into the back into the gap penalties. And we asked, does that change the alignment, and does that change the downstream analysis that you're doing, such as trees. And, well, how, how do you set the scale for these perturbations and the, the standard. Well, how did we come up with them in the first place we we tuned them on some benchmark test. And the standard should be that we make them as large as possible because we want replicates that are different. But we don't want to degrade the accuracy, accuracy on our benchmark because once you start to degrade accuracy, people are not going to use your method. So you want to be in that sweet spot where you maximize the variation without paying a price in accuracy. Okay, so I promised a gentle introduction so we're going to have a couple of slides here which are not gentle at all but we'll quickly go back to, to more gentle presentation but so how do I actually do that. And the, the, this is okay so this is all kind of mathematical it's based on a thing called a hidden markup model. And this was introduced by by a group from Stanford, way back in 2005 around about the same time that I was doing the first version of muscle, and it's a very, from a mathematical point of view it's a very elegant framework where everything is probabilities. But really it's just, it's nothing fancier from an evolutionary point of view is it's basically just this very simplified model where you have a substitution matrix gap penalties here you actually have four instead of two, but you know it's not that different. And so this gives me a nice little way where I can introduce random perturbations in a sort of a principle way and keep everything under control and not just doing sort of arbitrary things. And this is how muscle five works okay so that's everything I basically just said. So now the idea is instead of just running one alignment. We run a whole set of replicates that's what I call the ensemble, so we just keep changing the parameters, a little bit, making a different alignment. And if we see that the alignment is the same every time, this gives us a lot more confidence that the alignment is correct because it's robust against these changes in the model which really shouldn't matter. And you can focus on individual columns, maybe some columns are consistently reproduced and some are less so you can actually assign a confidence level to each column in the alignment. And then even if the alignment barriers that doesn't necessarily mean that's bad, it may still be good enough for a given purpose so what you should do is well you continue the analysis and you estimate your tree. And you can not only can you see if the tree is consistent, but you can see if the bootstrap values are trustworthy. Because if the trees come out different but with high bootstraps, then you should not trust the bootstraps you should believe the ensemble of trees is telling you which is that some parts of the tree are not reproducible, so it gives you a different way of approaching this whole sort of pipeline. So now I need to sort of digress into another sort of technical issue which is. Well, the hidden markup model or blast or whatever that's how you align two sequences. But how do you build a multiple alignment, and the answer is, essentially every popular method, there is muscle prop cones math. They all assemble the final alignment, using the strategy which is called progressive alignment, and the way that this works is you at every step you do a pairwise alignment, and when you start at the very beginning at the bottom of the tree you have individual sequences. And as you work your way up the tree. You have. So let's say at the first node, now you have a pair of sequences align, while you keep them aligned to each other, and you align them to something else so at each stage you keep the alignments intact and you have a pairwise alignments of the two alignments. And this, this process can be could be regarded as a tree or following a binary tree and that tree is called the guide tree. Sometimes it's explicitly constructed beginning sometimes you sort of dynamically figure out which pair, you're going to join at each iteration but the bottom line is there's always a guide tree of one kind or another involved. And this is a problem for phylogenetics because well if you have a more challenging alignment. Every time you make one of these joins the quality goes down, you have fewer and fewer correct columns or good enough columns. So it means that the sort of the systematic errors the pattern of good columns well conserved columns and errors in the final tree reflects the guide tree that you use to build it. So if you then take that alignment and you give it to RaxML or quick tree or whatever. Those systematic errors can get reflected in the maximum likelihood tree. So well how does that bootstrapping actually work for bootstrapping takes a sort of a random samples from the columns in your alignment and asks whether that subsample reproduces the same tree or not. If you have systematic errors, then you can have the same patterns of this sort of underlying guide tree reproduced in different columns, and this is the mechanism where systematic errors in the alignment can produce systematic errors in the tree, and can give you spuriously high bootstrap values. So, this is what I just said. So muscle five does something else. It doesn't just perturb the HMM parameters. It also makes variations in this guide tree. And you have to do this in a rather carefully designed way. Because you sort of have conflicting goals. So one of the reasons you have a guide tree is that you get the most accurate alignment, when you align the most closely related sequences so if you just take two groups of random and align them they might be more closely related and you're writing errors more quickly. So you every step you want to get something close to the most closely related groups in order to get the highest accuracy. You also want to vary this tree in a meaningful way so that it has a chance to sort of expose the systematic errors. So, the way that muscle five does this is that it preserves the guide tree close to the leaves, but as you get close to the final alignment so the last two or three joins, it switches around the order. So, it does. So this is sort of the notation that I use. And there's four variants like this for the final assembly stage of the multiple alignment. So now, the ways that replicates are generated it's a combination of a perturbation of the HMM parameters and this joining order of the tree. So now to some benchmark results. So, the sort of gold standard in protein multiple alignment is this benchmark set called barley base, and it's worth noting that the best sequence, the best alignment methods, and here I'm showing you know there's a few other competitors but those are definitely among the state-of-the-art. But you'll notice that the left is the y-axis and that's the fraction of columns that are correctly aligned on this set. And we're only in sort of the 50 to 60% range. So, this tells you that there is a lot of uncertainty and even the best methods don't reproduce structural alignments on this benchmark. But there are sort of two lessons here I want to sort of draw out on this slide. One is, well, muscle 5 is slightly better than the competition here. I mean, I don't think it's better in any meaningful way, to be honest. But it addresses this psychological problem that you want to feel like using the best method that you shouldn't discount the other ways of doing it because they might be worse. And the other thing is that it doesn't make any practical difference whether you use the defaults or whether you perturb the HMM parameters and the guide trees. So, any one of these ways of building an alignment is equally good as far as we know. It performs equally well on the benchmark. Of course, some of them do better and worse on particular sets. But when you're starting with new data, you have no particular reason to prefer any of these variants. And this means that you can generate your ensemble of alignments and they're equally trustworthy. So, now you can say, well, if they give different results, I have a problem. Or if they're giving consistent results, then, you know, I have good reason to feel more confident in them. I haven't really talked about nucleotide alignments, but it's a similar story. So, now I'm going back to sort of a concrete application of this whole approach. And so, I need to give a little background on RNA virus taxonomy. And it's undergone some radical changes recently. So, before 2018, so maybe I should quickly review taxonomy for people who have not heard of this. It's sort of a human classification state scheme. And it's sort of based on a tree-like sort of structure, which is supposed to follow phylogeny. And then it has ranks, which are species, genus, family, class, order, phylum, which are sort of human-level groups, but they're supposed to capture something meaningful about the organisms that you're classifying. And they're supposed to follow the phylogenetic tree so that these groups are, you know, they're evolutionary relatives, not just things that you think look alike. And before 2018, RNA viruses were not classified above order. There was no class or phylum rank. And the reason for that is that, well, how do you build trees for these viruses? Well, you use polymerase sequences, but these sequences evolve very quickly. And it becomes very, very difficult to make alignments and trees for the most distantly related groups. And then in 2018, a paper came along, which was highly influential, and it's Wolf 2018. And they went to a lot of effort to build a sort of global multiple alignment of all RNA viruses from their polymerases and build a tree from it. And this is sort of a figure from the paper, and I'm sort of capturing, I'm calling out here the bootstrap values on the deepest branches of this tree, which look very high. And so that was very convincing to these guys and also to the sort of official virus taxonomists. And what they did was, you can see we've got those five colored branches. Those were adopted as phylum rank. So on the basis of this paper, RNA virus taxonomy was expanded to include phylum and class ranks. And when I saw this paper, it bothered me for about a year. So this is sort of the kind of the history behind how muscle five came about. Because I've played quite a bit with these polymerases, and I know how diverged they are. And I just looked at that and I said, I do not believe that tree. I just don't know, you just cannot align these things well enough to get this kind of reliability in a tree. How do you prove this is wrong? So, of course, now you've heard the rest of the talk, you have an idea about how I went to do that. But really, I just went around muttering, I don't believe it, this can't be right. And this was sort of what I ultimately came up with as a response to my skepticism, if you like. So, yeah, so just to emphasize how difficult it is, the average distance between highly diverged viruses is five substitutions per site. So if you know anything about sort of protein alignment, protein evolution, so once you get something like 50% amino acid identity, which is 0.5 substitutions per site, it's already starting to get a little bit tricky. You've got some good regions, you've got some bad regions. Then if I get down anywhere close to one substitution per site, on average, I've got a different letter at every position and I'm well down into what's called the twilight zone. And we're starting to get alignments that look like the WTF, the things that I was showing earlier. But we have gone five times deeper than that. And so the conventional ability, excuse me, the conventional wisdom before 2018 was, well, the information's just lost. So one of the things I did sort of in my skepticism was to really dig deep into that alignment. And I'm not going to go into the technical details here at all. I'm just going to sort of say that while there are a few very well conserved catalytic residues in RNA virus polymerase, and I was able to show that many of those catalytic residues are not correctly aligned within this alignment. So this means that of something like 400 columns, none of them are aligned correctly. Because if you don't get the catalytic residues right, where you have the best conservation, you certainly haven't got the rest of it right. So this sort of bolstered my opinion that something was going wrong in it. So after having sort of refined, come up with muscle five and put it together, I could now apply it to the Wolf 2018 alignment and the tree. So I needed to do two things. First of all, I had to show that my alignment was at least as good as theirs, because they went to all this effort to do the manual adjustment and whatever. And these guys have a very high reputation as the experts on RNA viruses. So I make absolutely no claim that my alignment is good in any sense, but I can show that I get the catalytic residues right more often than they do. So I think there's a reasonable case that mine is at least as good as theirs. But then when I generate replicates, these groups just get shuffled. So my claim is that when you do the analysis using the muscle five ensemble, you can see that the fiber are not reproduced. And this means that the high bootstraps you get in the Wolf 2018 tree must be artifacts of systematic errors in their alignment. And of course, like everybody else, they use progressive alignment to put things together. So I think that groups really reflect the big blocks that they assembled in the final stages of putting together their alignment. So when I do the confidences my way, they're very low. So my methodology says I shouldn't believe my tree, and I believe that it shouldn't be believed. So this is, of course, my minority opinion, and I'm currently trying to convince people that currently RNA virus taxonomy is kind of driven off the rails, and it's not meaningful at all. And I think that's actually positively harmful. To get into that would be sort of a whole nother talk, but I'm just trying to use this as a case study to show how this approach can be applied to something in practice. And so we actually got through this quicker than I thought. That's the muscle five paper. And thank you very much for the invitation. Thank you. Now I think we'll be the QA session. I think it's really amazing that, for me, I just go to use whatever multiple sequence alignment, and then you give me a high bootstrap value, I believe it, and call it a day. And I really appreciate that this talk lead us into the details and how to be skeptical. And I think Kelvin and Luther have a question in the chat. Do you want to unmute yourself or maybe turn on the camera to speak for yourself? I'm sorry, I didn't quite catch that, but I do see a great question on the chat. It's a great question because now I wish I had done a couple of slides on this. And actually, this is what we're doing in the Serratus project right now. So you remember I gave a very quick slide on this project we did during the pandemic to discover new RNA viruses. And now we have this incredible resource with AlphaFold where we can discover much more highly diverged viruses by doing this folding. So, AlphaFold is very good at enabling us to find very highly diverged homologs. What the structural alignment, and I talked very briefly about this, but when you have distantly related structures, you can eyeball them in higher model, and you can see, okay, very clearly, you have a squiggle here and a squiggle here and the squiggles and the squoggles line up between the different structures. But you can't say, okay, but this cysteine residue exactly matches that aspartate residue in the other structure. It's not that precise. So you might have a helix here and a helix here. So you can say, yeah, these secondary structures are the same. But now the homology is at that level. You can say secondary structure, yeah. But once you get to the level of an individual residue, it's not clear. And it's probably not meaningful because there's been enough insertion and deletion that it's not really clear that there's a one-to-one evolutionary correspondence between the residues. What's being conserved here is the secondary structures. So what does that mean? It means you can recognize the polymerases and you can do that with a very high degree of confidence from the structures. But what you can't do is build trees because you can't get evolutionary distances between structures. You can only get evolutionary distances from sequences. And even that's questionable. So what do you actually do to build those kinds of trees? You do maximum likelihood. And what's maximum likelihood? This is Moses coming down with some tablets that have a very, very simplified model of evolution written on them, saying, OK, well, there's this transition probability, that transversion probability. And there's all kinds of fancy math. But what that math boils down to is an incredibly oversimplified model of evolution. And, well, that's the best we can do. And it surely works very well in reasonable cases. But here we're at five or six substitutions per site. So we are pushing sort of a model which no doubt works very well over short distances to extremely large distances. And that surely just doesn't work. And with structures we don't have an evolutionary distance. So you can say, well, this maybe looks more similar to that. But it doesn't tell you whether it's an evolutionary neighbor or not. So there's this classic issue which people can sometimes forget. So let's say you have a blast top hit. Is it to a polymerase, a virus polymerase, or to a group two intron, or a CRISPR-Cas protein? These are all in the same superfamily. They're all pandamine proteins. And you can look at the top hit and say, OK, the top hit is a virus. It's probably a virus, which is true. But it's not necessarily a virus. It could be a highly diverged group two intron. It's just that the way blast ranks them is not the way it doesn't necessarily reflect what's the closest in the tree. When you're looking at structures, you have the same problem. You can say, well, this structure looks more like that structure. And you can say, OK, it has a DALI z-score or a TMI score or whatever, which is closer. But that doesn't necessarily mean it's the closest evolutionary relative. So alpha fold is adding a lot of capability here. But it doesn't resolve the deep evolutionary history of these viruses. So the question is, does muscle work equally well for nucleotides as for amino acid sequences? So the question here is, well, what's your standard of accuracy? And so I don't think you can directly compare them. If you saw on BarbieBase, the best methods only get 50% to 60% of columns correct. But they're incredibly challenging alignments, where probably most of the columns are not even meaningful anyway. So it really depends. What's your benchmark? What's your standard of accuracy? I mean, it works well. And it also is slightly better than the competition. When you do a benchmark, does that matter in practice? I would say no. I would say the important thing is that you have this ability to muscle will, by generating the ensemble, muscle will tell you whether it's good enough for your problem or not. And this is a gaping hole in bioinformatics tool in general, is you might have a confidence or a probability, but you're trusting all the assumptions in the algorithm are good enough that it can be trusted to come up with its own confidence. And sometimes that's not the case, because like when you saw with bootstrap values, sometimes you get high bootstraps for wrong trees. So here muscle is helping you answer the question, is the method good enough to answer the biological question I'm trying to answer? Could I comment on methods that estimate phylogeny and alignment simultaneously? So that would require a very long answer to go in detail. But I would say generally, so conceptually, it's the right thing to do. In practice, it's so computationally expensive, these methods, they're too slow to be usable in practice. And the accuracy is quite bad, because they just can't, it's just too hard to implement. And when you do it, when you do that kind of thing, you're still using these grotesquely oversimplified models. So I want you to keep in mind, MOSE is coming down with these laws, and proteins don't respect these laws whatsoever. Proteins live in a very, very complicated world with selection pressure and biochemistry and everything going on. They don't think about blossom scores. So if you're a method that's trying to estimate phylogeny and alignment at the same time, it's starting from the wrong place. It's starting from this highly simplified model of evolution. And however much sort of added bells and whistles you put into that model, it's still extremely oversimplified. So you're kind of pushing in a direction which is, it's like the physicist with the spherical cow. Okay, so we're adding two spherical horns to the spherical cow, but we're still a long way from the cow. Awesome. And Zarif, please ask your question. I was just wondering, and by no means, my research is on phylogeny and evolution, but I'm just wondering when you are doing these trees and alignments, so can you take information from some other closely related proteins when you are doing the phylogeny and take information from trees constructed from other proteins to make your phylogeny or alignment better? So the short answer is no. And there are two reasons for that. One is the polymerase is the only gene that you find in all RNA viruses. So even within a family like coronavirus, there's quite a lot of variation in the gene content. If you go deep, there is nothing except the polymerase. So that's one problem. The other problem is that the other genes typically evolve much more quickly than the polymerase. So they're much harder to align, and it's just not adding anything useful. I mean, even between two different species, you get about 90% polymerase identity. So that's enough distance that you can clearly separate species. The other genes really isn't adding anything helpful, and they're evolving much more quickly, so they're harder to align. So in any case I can think of, you're better off throwing the other genes away and just focusing on the polymerase. It's only if you're looking at a very, very fine grained detail, like let's say Omicron variant of COVID versus some other variant, then you're looking at the other genes. But as soon as you go any deeper than that, you're better off focusing just on the polymerase. Nice. Can you check Olivia's question in the chat? What do I think the ideal method of RNA virus classification is? So I just addressed the issue of whether it helps use the rest of the genome. And I think that, well, so yes. So here the issue is, when your traditional taxonomy, you culture a microbe and you grow it in some cells and you take photographs of it, you see what kinds of cells it infects. So it's very labor intensive focus on a single virus. So a project like Serratus finds 100,000 viruses, we're not doing that kind of analysis. Basically we're giving you a polymerase sequence. So, and we don't know very much else about it, typically. But kind of by definition, that's what we've got to work with and we want to classify those sequences. And this is generally a problem in all of microbial biology right now is that we're uncovering this vast world of viruses and bacteria, fungi, which are only known from metagenomic sequences. And you can say, well, how do we do taxonomy with those and maybe just don't do taxonomy, maybe do computational classification and you call it something else. I think this was the mistake that the virus people made, to be honest, because with bacteria and fungi, we have that problem, but people don't try to make official taxonomy. But the virus guys elevated these debatable polymerase trees and made official taxonomy out of them. So I think they should have made a distinction between the sort of big picture computational things and what the fine grain study in the lab. And this is really confusing to people that are not intimately familiar with how virus taxonomy is done. So it's a scope to improve strategy for guide tree estimation and merging of subalignments. I think this is so I'm sure there is. I mean, obviously, if I had ideas, I would have done them. But I want to sort of seize on the sort of a conceptual issue in this question, which is always the search for the best method. And of course, this is a very good search. And I'm a very competitive guy. I want to have the best method when I make one. But one thing I've tried to draw attention to in this talk is there's a risk with just focusing on the best method if you're not sure how good it is or how good it is for your specific question. So what it's important, I think, to keep in mind that the best method is still a radical oversimplification of biology, whatever you do, however good it is, however much progress we make on multiple alignment over the next 10 years. This will still be the case because the only way to really do it is just like simulate the entire planet for 3 billion years and see what evolution actually does. We can't do that. We make these very, very simplified computational models. And we should try to make them as good as possible. We should also try to have them interrogate themselves as to how good they are. Okay, another question. So after generating the alignment, yes, it's possible to identify problematic regions. And yes, you can refine those regions. And yes, you can refine those regions. But some regions are simply not meaningful because there's no homology there or no sequence similarity there. So you may be better off identifying those regions. And muscle 5 does this. It assigns a column confidence score to every column. And, of course, it depends why did you make the alignment and what inference do you make from it so it's always a bit risky to give general rules but as a general rule maybe you should just ignore those columns because it's not given that every column has to mean something, because you may remember I said, well, there are quite a few types of mutation that the alignment cannot represent. So, if you go too far and try to force the alignment into some kind of shape, it may just not be meaningful because the mutations that happened, don't fit. Awesome. I think, let the chance question be the last question, it will be a nice ending. So, okay, let me read the question for identifying what follows just genes. Okay, no, is my answer to that question. That was an easy one. Would you like to elaborate a little bit. Okay, I think that's about the end of our seminar and thank you so much, Robert, and everybody if you don't mind you can unmute yourself and give Dr. Robert a round of applause. Okay, thank you very much. Thank you. Please have a nice day. Bye bye everyone. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 25.0, "text": " Okay, let me take a look at the audience.", "tokens": [50364, 1033, 11, 718, 385, 747, 257, 574, 412, 264, 4034, 13, 51614], "temperature": 0.0, "avg_logprob": -0.5702093760172526, "compression_ratio": 0.8723404255319149, "no_speech_prob": 0.06693851202726364}, {"id": 1, "seek": 2500, "start": 25.0, "end": 54.0, "text": " I think we have most of them so I should probably get started.", "tokens": [50364, 286, 519, 321, 362, 881, 295, 552, 370, 286, 820, 1391, 483, 1409, 13, 51814], "temperature": 0.0, "avg_logprob": -0.5423479080200195, "compression_ratio": 0.9393939393939394, "no_speech_prob": 0.4216923713684082}, {"id": 2, "seek": 5400, "start": 54.0, "end": 58.0, "text": " Okay, sounds good. Thanks Dr. Gannon.", "tokens": [50364, 1033, 11, 3263, 665, 13, 2561, 2491, 13, 460, 16138, 13, 50564], "temperature": 0.0, "avg_logprob": -0.3596635546003069, "compression_ratio": 1.0588235294117647, "no_speech_prob": 0.06746815890073776}, {"id": 3, "seek": 5400, "start": 58.0, "end": 62.0, "text": " And I think Jared's already started recording.", "tokens": [50564, 400, 286, 519, 24160, 311, 1217, 1409, 6613, 13, 50764], "temperature": 0.0, "avg_logprob": -0.3596635546003069, "compression_ratio": 1.0588235294117647, "no_speech_prob": 0.06746815890073776}, {"id": 4, "seek": 5400, "start": 62.0, "end": 64.0, "text": " Okay.", "tokens": [50764, 1033, 13, 50864], "temperature": 0.0, "avg_logprob": -0.3596635546003069, "compression_ratio": 1.0588235294117647, "no_speech_prob": 0.06746815890073776}, {"id": 5, "seek": 5400, "start": 64.0, "end": 66.0, "text": " Welcome everyone.", "tokens": [50864, 4027, 1518, 13, 50964], "temperature": 0.0, "avg_logprob": -0.3596635546003069, "compression_ratio": 1.0588235294117647, "no_speech_prob": 0.06746815890073776}, {"id": 6, "seek": 6600, "start": 66.0, "end": 86.0, "text": " I'm so happy to see you all here at the I will be faculty seminar. And today I have the honor to introduce Dr. Robert Edgar, Dr. Robert Edgar has a Bachelor of Science in physics and a PhD in particle physics from University College London.", "tokens": [50364, 286, 478, 370, 2055, 281, 536, 291, 439, 510, 412, 264, 286, 486, 312, 6389, 29235, 13, 400, 965, 286, 362, 264, 5968, 281, 5366, 2491, 13, 7977, 42981, 11, 2491, 13, 7977, 42981, 575, 257, 23193, 295, 8976, 294, 10649, 293, 257, 14476, 294, 12359, 10649, 490, 3535, 6745, 7042, 13, 51364], "temperature": 0.0, "avg_logprob": -0.3117778641836984, "compression_ratio": 1.4035087719298245, "no_speech_prob": 0.0034291637130081654}, {"id": 7, "seek": 8600, "start": 86.0, "end": 104.0, "text": " He served as a CTO of IDBS APS in Copenhagen, from 1982 to 1988, where he designed and implemented a groundbreaking database server and application development environment.", "tokens": [50364, 634, 7584, 382, 257, 383, 15427, 295, 7348, 8176, 5372, 50, 294, 50135, 4698, 11, 490, 31352, 281, 27816, 11, 689, 415, 4761, 293, 12270, 257, 42491, 8149, 7154, 293, 3861, 3250, 2823, 13, 51264], "temperature": 0.0, "avg_logprob": -0.286686194570441, "compression_ratio": 1.2374100719424461, "no_speech_prob": 0.5888010263442993}, {"id": 8, "seek": 10400, "start": 104.0, "end": 126.0, "text": " In 1988, Dr. Edgar founded parity software in San Francisco, where he served as CEO, chief architect and lead developer. He software development tools for computer telephony applications won numerous industrial awards and he grew the business to 30 employees", "tokens": [50364, 682, 27816, 11, 2491, 13, 42981, 13234, 44747, 4722, 294, 5271, 12279, 11, 689, 415, 7584, 382, 9282, 11, 9588, 6331, 293, 1477, 10754, 13, 634, 4722, 3250, 3873, 337, 3820, 4304, 28616, 5821, 1582, 12546, 9987, 15193, 293, 415, 6109, 264, 1606, 281, 2217, 6619, 51464], "temperature": 0.0, "avg_logprob": -0.2877150578285331, "compression_ratio": 1.4279475982532752, "no_speech_prob": 0.515439510345459}, {"id": 9, "seek": 10400, "start": 126.0, "end": 133.0, "text": " and 10 million per year in sales before selling it to Intel in 1999.", "tokens": [51464, 293, 1266, 2459, 680, 1064, 294, 5763, 949, 6511, 309, 281, 19762, 294, 19952, 13, 51814], "temperature": 0.0, "avg_logprob": -0.2877150578285331, "compression_ratio": 1.4279475982532752, "no_speech_prob": 0.515439510345459}, {"id": 10, "seek": 13300, "start": 133.0, "end": 151.0, "text": " Dr. Edgar has things focused his attention on computational biology and bioinformatics, and it's best known for developing the widely used muscle and you search programs, which have been cited in thousands of published papers, his contributions to the field", "tokens": [50364, 2491, 13, 42981, 575, 721, 5178, 702, 3202, 322, 28270, 14956, 293, 12198, 37811, 30292, 11, 293, 309, 311, 1151, 2570, 337, 6416, 264, 13371, 1143, 8679, 293, 291, 3164, 4268, 11, 597, 362, 668, 30134, 294, 5383, 295, 6572, 10577, 11, 702, 15725, 281, 264, 2519, 51264], "temperature": 0.0, "avg_logprob": -0.24132227430156633, "compression_ratio": 1.4685714285714286, "no_speech_prob": 0.247905895113945}, {"id": 11, "seek": 15100, "start": 151.0, "end": 177.0, "text": " are significant and recognized with the night 2019 study reporting him as one of the top 0.01% of living scientists for the impact of his work today Dr.", "tokens": [50364, 366, 4776, 293, 9823, 365, 264, 1818, 6071, 2979, 10031, 796, 382, 472, 295, 264, 1192, 1958, 13, 10607, 4, 295, 2647, 7708, 337, 264, 2712, 295, 702, 589, 965, 2491, 13, 51664], "temperature": 0.0, "avg_logprob": -0.3844647937350803, "compression_ratio": 1.2773109243697478, "no_speech_prob": 0.6028362512588501}, {"id": 12, "seek": 17700, "start": 178.0, "end": 180.0, "text": " Thank you. Thank you very much.", "tokens": [50414, 1044, 291, 13, 1044, 291, 588, 709, 13, 50514], "temperature": 0.0, "avg_logprob": -0.22542757737009148, "compression_ratio": 1.4951923076923077, "no_speech_prob": 0.7118996977806091}, {"id": 13, "seek": 17700, "start": 180.0, "end": 185.0, "text": " Pleasure to be here in Athens I think it's my first time out.", "tokens": [50514, 25658, 2508, 281, 312, 510, 294, 32530, 286, 519, 309, 311, 452, 700, 565, 484, 13, 50764], "temperature": 0.0, "avg_logprob": -0.22542757737009148, "compression_ratio": 1.4951923076923077, "no_speech_prob": 0.7118996977806091}, {"id": 14, "seek": 17700, "start": 185.0, "end": 205.0, "text": " But so today I'm going to talk about sequence alignment, and a little bit about the latest version of muscle, but I want to sort of draw some larger lessons about how people general generally use bioinformatics tools.", "tokens": [50764, 583, 370, 965, 286, 478, 516, 281, 751, 466, 8310, 18515, 11, 293, 257, 707, 857, 466, 264, 6792, 3037, 295, 8679, 11, 457, 286, 528, 281, 1333, 295, 2642, 512, 4833, 8820, 466, 577, 561, 2674, 5101, 764, 12198, 37811, 30292, 3873, 13, 51764], "temperature": 0.0, "avg_logprob": -0.22542757737009148, "compression_ratio": 1.4951923076923077, "no_speech_prob": 0.7118996977806091}, {"id": 15, "seek": 20500, "start": 206.0, "end": 227.0, "text": " How do I find like that. Okay, so I understand we have a variety of backgrounds here so some people may be more or less familiar with this kind of thing so I'm going to assume you basically know the idea of a sequence alignment.", "tokens": [50414, 1012, 360, 286, 915, 411, 300, 13, 1033, 11, 370, 286, 1223, 321, 362, 257, 5673, 295, 17336, 510, 370, 512, 561, 815, 312, 544, 420, 1570, 4963, 365, 341, 733, 295, 551, 370, 286, 478, 516, 281, 6552, 291, 1936, 458, 264, 1558, 295, 257, 8310, 18515, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2543438605542453, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.4764957129955292}, {"id": 16, "seek": 22700, "start": 228.0, "end": 241.0, "text": " And here I'm going to focus on various polymerases, and you can sort of see here we have an alignment and gel view and you can sort of see by eyeball this looks very reasonable.", "tokens": [50414, 400, 510, 286, 478, 516, 281, 1879, 322, 3683, 20073, 1957, 11, 293, 291, 393, 1333, 295, 536, 510, 321, 362, 364, 18515, 293, 4087, 1910, 293, 291, 393, 1333, 295, 536, 538, 38868, 341, 1542, 588, 10585, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2629506167243509, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.853774905204773}, {"id": 17, "seek": 22700, "start": 241.0, "end": 250.0, "text": " I mean, you don't need muscle any any alignment, you can do it manually, it's pretty straightforward.", "tokens": [51064, 286, 914, 11, 291, 500, 380, 643, 8679, 604, 604, 18515, 11, 291, 393, 360, 309, 16945, 11, 309, 311, 1238, 15325, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2629506167243509, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.853774905204773}, {"id": 18, "seek": 25000, "start": 251.0, "end": 258.0, "text": " And I'm focusing on various polymerase because right now with the pandemic.", "tokens": [50414, 400, 286, 478, 8416, 322, 3683, 20073, 651, 570, 558, 586, 365, 264, 5388, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20119548979259672, "compression_ratio": 1.5055555555555555, "no_speech_prob": 0.7087447047233582}, {"id": 19, "seek": 25000, "start": 258.0, "end": 272.0, "text": " It's kind of a, it's very relevant it's relevant for virus discovery and I'm not going to talk about this today but I just wanted to motivate why I'm particularly interested in virus polymerases.", "tokens": [50764, 467, 311, 733, 295, 257, 11, 309, 311, 588, 7340, 309, 311, 7340, 337, 5752, 12114, 293, 286, 478, 406, 516, 281, 751, 466, 341, 965, 457, 286, 445, 1415, 281, 28497, 983, 286, 478, 4098, 3102, 294, 5752, 20073, 1957, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20119548979259672, "compression_ratio": 1.5055555555555555, "no_speech_prob": 0.7087447047233582}, {"id": 20, "seek": 27200, "start": 272.0, "end": 291.0, "text": " So this was a really remarkable project that I was involved in still involved in it was started by an unemployed Canadian postdoc at the beginning of the pandemic with the goal of trying to understand where COVID-19 came from, and it attracted a sort", "tokens": [50364, 407, 341, 390, 257, 534, 12802, 1716, 300, 286, 390, 3288, 294, 920, 3288, 294, 309, 390, 1409, 538, 364, 34411, 12641, 2183, 39966, 412, 264, 2863, 295, 264, 5388, 365, 264, 3387, 295, 1382, 281, 1223, 689, 4566, 12, 3405, 1361, 490, 11, 293, 309, 15912, 257, 1333, 51314], "temperature": 0.0, "avg_logprob": -0.2605834069190087, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.5232599973678589}, {"id": 21, "seek": 27200, "start": 291.0, "end": 299.0, "text": " of an all star team of volunteers scientists from all over the world who kind of put their time into this.", "tokens": [51314, 295, 364, 439, 3543, 1469, 295, 14352, 7708, 490, 439, 670, 264, 1002, 567, 733, 295, 829, 641, 565, 666, 341, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2605834069190087, "compression_ratio": 1.5657894736842106, "no_speech_prob": 0.5232599973678589}, {"id": 22, "seek": 29900, "start": 299.0, "end": 320.0, "text": " And there's a happy ending to the story because Dr babian who was then unemployed is now an assistant professor in Toronto, and the sort of the headline of our paper last year was we increase the number of known RNA virus species by about an order of magnitude", "tokens": [50364, 400, 456, 311, 257, 2055, 8121, 281, 264, 1657, 570, 2491, 7564, 952, 567, 390, 550, 34411, 307, 586, 364, 10994, 8304, 294, 14140, 11, 293, 264, 1333, 295, 264, 28380, 295, 527, 3035, 1036, 1064, 390, 321, 3488, 264, 1230, 295, 2570, 22484, 5752, 6172, 538, 466, 364, 1668, 295, 15668, 51414], "temperature": 0.0, "avg_logprob": -0.27978600774492535, "compression_ratio": 1.452513966480447, "no_speech_prob": 0.017436230555176735}, {"id": 23, "seek": 32000, "start": 320.0, "end": 337.0, "text": " before we did this for about 10,000 species and now we know 130,000 and so this got me kind of interested in how can we align and classify all these new guys.", "tokens": [50364, 949, 321, 630, 341, 337, 466, 1266, 11, 1360, 6172, 293, 586, 321, 458, 19966, 11, 1360, 293, 370, 341, 658, 385, 733, 295, 3102, 294, 577, 393, 321, 7975, 293, 33872, 439, 613, 777, 1074, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2920866012573242, "compression_ratio": 1.427027027027027, "no_speech_prob": 0.5542479157447815}, {"id": 24, "seek": 32000, "start": 337.0, "end": 346.0, "text": " And COVID, it is an RNA virus and you know this is sort of the background for why I'm using this example.", "tokens": [51214, 400, 4566, 11, 309, 307, 364, 22484, 5752, 293, 291, 458, 341, 307, 1333, 295, 264, 3678, 337, 983, 286, 478, 1228, 341, 1365, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2920866012573242, "compression_ratio": 1.427027027027027, "no_speech_prob": 0.5542479157447815}, {"id": 25, "seek": 34600, "start": 347.0, "end": 367.0, "text": " So how do you actually make a sequence alignment. Well, under the hood, it's, it's important to understand that these algorithms are really using an X, a highly simplified model of evolution, I mean oversimplified really because you, we proteins are really complicated.", "tokens": [50414, 407, 577, 360, 291, 767, 652, 257, 8310, 18515, 13, 1042, 11, 833, 264, 13376, 11, 309, 311, 11, 309, 311, 1021, 281, 1223, 300, 613, 14642, 366, 534, 1228, 364, 1783, 11, 257, 5405, 26335, 2316, 295, 9303, 11, 286, 914, 15488, 332, 564, 2587, 534, 570, 291, 11, 321, 15577, 366, 534, 6179, 13, 51414], "temperature": 0.0, "avg_logprob": -0.27867323557535806, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.6892079710960388}, {"id": 26, "seek": 36700, "start": 368.0, "end": 380.0, "text": " So these are just some sort of very, I guess crude averages over how proteins behave because that's really the only way we know how to do it as a practical matter.", "tokens": [50414, 407, 613, 366, 445, 512, 1333, 295, 588, 11, 286, 2041, 30796, 42257, 670, 577, 15577, 15158, 570, 300, 311, 534, 264, 787, 636, 321, 458, 577, 281, 360, 309, 382, 257, 8496, 1871, 13, 51014], "temperature": 0.0, "avg_logprob": -0.22877145424867287, "compression_ratio": 1.3252032520325203, "no_speech_prob": 0.7930138111114502}, {"id": 27, "seek": 38000, "start": 381.0, "end": 393.0, "text": " And then there's a, the, the way that proteins evolve as you have these substitution scores which says, you know how likely it is for one residue to be replaced by another.", "tokens": [50414, 400, 550, 456, 311, 257, 11, 264, 11, 264, 636, 300, 15577, 16693, 382, 291, 362, 613, 35827, 13444, 597, 1619, 11, 291, 458, 577, 3700, 309, 307, 337, 472, 34799, 281, 312, 10772, 538, 1071, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2910980395416715, "compression_ratio": 1.5297297297297296, "no_speech_prob": 0.5504807829856873}, {"id": 28, "seek": 38000, "start": 393.0, "end": 401.0, "text": " And you have this very simple model of insertions and deletions which penalizes, adding gaps to the alignment.", "tokens": [51014, 400, 291, 362, 341, 588, 2199, 2316, 295, 8969, 626, 293, 1103, 302, 626, 597, 13661, 5660, 11, 5127, 15031, 281, 264, 18515, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2910980395416715, "compression_ratio": 1.5297297297297296, "no_speech_prob": 0.5504807829856873}, {"id": 29, "seek": 40100, "start": 402.0, "end": 418.0, "text": " It's just really not that simple I mean Moses did not come down from a mountain and tell proteins to obey these laws so it's, it's just something to bear in mind that what's really going on here is something much more complicated and you should always be skeptical", "tokens": [50414, 467, 311, 445, 534, 406, 300, 2199, 286, 914, 17580, 630, 406, 808, 760, 490, 257, 6937, 293, 980, 15577, 281, 19297, 613, 6064, 370, 309, 311, 11, 309, 311, 445, 746, 281, 6155, 294, 1575, 300, 437, 311, 534, 516, 322, 510, 307, 746, 709, 544, 6179, 293, 291, 820, 1009, 312, 28601, 51214], "temperature": 0.0, "avg_logprob": -0.2126059850056966, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.37376663088798523}, {"id": 30, "seek": 40100, "start": 418.0, "end": 429.0, "text": " that the alignment is really correct or informative I mean sometimes it's obvious like that first example I showed, but you should always be kind of skeptical.", "tokens": [51214, 300, 264, 18515, 307, 534, 3006, 420, 27759, 286, 914, 2171, 309, 311, 6322, 411, 300, 700, 1365, 286, 4712, 11, 457, 291, 820, 1009, 312, 733, 295, 28601, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2126059850056966, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.37376663088798523}, {"id": 31, "seek": 42900, "start": 429.0, "end": 438.0, "text": " So here, so this is that same alignment, which this is a bunch of Corona viruses and it's two regions from the same alignment.", "tokens": [50364, 407, 510, 11, 370, 341, 307, 300, 912, 18515, 11, 597, 341, 307, 257, 3840, 295, 18075, 21785, 293, 309, 311, 732, 10682, 490, 264, 912, 18515, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2674035379442118, "compression_ratio": 1.496969696969697, "no_speech_prob": 0.4377131164073944}, {"id": 32, "seek": 42900, "start": 438.0, "end": 445.0, "text": " So the one I showed the top yeah that's that's convincing everyone would do it manually all programs are going to agree.", "tokens": [50814, 407, 264, 472, 286, 4712, 264, 1192, 1338, 300, 311, 300, 311, 24823, 1518, 576, 360, 309, 16945, 439, 4268, 366, 516, 281, 3986, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2674035379442118, "compression_ratio": 1.496969696969697, "no_speech_prob": 0.4377131164073944}, {"id": 33, "seek": 44500, "start": 445.0, "end": 454.0, "text": " And if you look at the other region there, I've shown at the bottom it's like well, how, I mean, really, how do we know, does the computer know.", "tokens": [50364, 400, 498, 291, 574, 412, 264, 661, 4458, 456, 11, 286, 600, 4898, 412, 264, 2767, 309, 311, 411, 731, 11, 577, 11, 286, 914, 11, 534, 11, 577, 360, 321, 458, 11, 775, 264, 3820, 458, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2686692857250725, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.577329695224762}, {"id": 34, "seek": 44500, "start": 454.0, "end": 470.0, "text": " And the answer is no the computer doesn't know any more than we do because it's using these very simplified models and what it does the best it can but if you get, if you get this to two different programs, it's going to give you different results", "tokens": [50814, 400, 264, 1867, 307, 572, 264, 3820, 1177, 380, 458, 604, 544, 813, 321, 360, 570, 309, 311, 1228, 613, 588, 26335, 5245, 293, 437, 309, 775, 264, 1151, 309, 393, 457, 498, 291, 483, 11, 498, 291, 483, 341, 281, 732, 819, 4268, 11, 309, 311, 516, 281, 976, 291, 819, 3542, 51614], "temperature": 0.0, "avg_logprob": -0.2686692857250725, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.577329695224762}, {"id": 35, "seek": 47000, "start": 470.0, "end": 474.0, "text": " Well, how would you choose.", "tokens": [50364, 1042, 11, 577, 576, 291, 2826, 13, 50564], "temperature": 0.0, "avg_logprob": -0.25350915169229316, "compression_ratio": 1.376068376068376, "no_speech_prob": 0.2719547748565674}, {"id": 36, "seek": 47000, "start": 474.0, "end": 477.0, "text": " So, this kind of raises.", "tokens": [50564, 407, 11, 341, 733, 295, 19658, 13, 50714], "temperature": 0.0, "avg_logprob": -0.25350915169229316, "compression_ratio": 1.376068376068376, "no_speech_prob": 0.2719547748565674}, {"id": 37, "seek": 47000, "start": 477.0, "end": 487.0, "text": " Sorry, excuse me.", "tokens": [50714, 4919, 11, 8960, 385, 13, 51214], "temperature": 0.0, "avg_logprob": -0.25350915169229316, "compression_ratio": 1.376068376068376, "no_speech_prob": 0.2719547748565674}, {"id": 38, "seek": 47000, "start": 487.0, "end": 497.0, "text": " So, this raises the question well, when is an alignment correct or when is it even useful.", "tokens": [51214, 407, 11, 341, 19658, 264, 1168, 731, 11, 562, 307, 364, 18515, 3006, 420, 562, 307, 309, 754, 4420, 13, 51714], "temperature": 0.0, "avg_logprob": -0.25350915169229316, "compression_ratio": 1.376068376068376, "no_speech_prob": 0.2719547748565674}, {"id": 39, "seek": 49700, "start": 497.0, "end": 507.0, "text": " And once you get in those more challenging regions like the bottom one I just showed that the answer is not necessarily that well defined, there's two main ways of thinking about it.", "tokens": [50364, 400, 1564, 291, 483, 294, 729, 544, 7595, 10682, 411, 264, 2767, 472, 286, 445, 4712, 300, 264, 1867, 307, 406, 4725, 300, 731, 7642, 11, 456, 311, 732, 2135, 2098, 295, 1953, 466, 309, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2265653201511928, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.6957948803901672}, {"id": 40, "seek": 49700, "start": 507.0, "end": 518.0, "text": " One is that the letters you see in a given column should all come from the same ancestral letters so that's technically called residue homology.", "tokens": [50864, 1485, 307, 300, 264, 7825, 291, 536, 294, 257, 2212, 7738, 820, 439, 808, 490, 264, 912, 40049, 7825, 370, 300, 311, 12120, 1219, 34799, 3655, 1793, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2265653201511928, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.6957948803901672}, {"id": 41, "seek": 51800, "start": 518.0, "end": 527.0, "text": " The other way you can say as well if you align the structures, the things that are in the same place in the structure should be in the same column.", "tokens": [50364, 440, 661, 636, 291, 393, 584, 382, 731, 498, 291, 7975, 264, 9227, 11, 264, 721, 300, 366, 294, 264, 912, 1081, 294, 264, 3877, 820, 312, 294, 264, 912, 7738, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2589560519443469, "compression_ratio": 1.8272727272727274, "no_speech_prob": 0.7876471877098083}, {"id": 42, "seek": 51800, "start": 527.0, "end": 542.0, "text": " But what, unless the structures really line up very well, that's kind of ambiguous so you start to have the same kind of ambiguity as you have with the letters so even structure doesn't really provide you a definitive standard and the sort of a gray area", "tokens": [50814, 583, 437, 11, 5969, 264, 9227, 534, 1622, 493, 588, 731, 11, 300, 311, 733, 295, 39465, 370, 291, 722, 281, 362, 264, 912, 733, 295, 46519, 382, 291, 362, 365, 264, 7825, 370, 754, 3877, 1177, 380, 534, 2893, 291, 257, 28152, 3832, 293, 264, 1333, 295, 257, 10855, 1859, 51564], "temperature": 0.0, "avg_logprob": -0.2589560519443469, "compression_ratio": 1.8272727272727274, "no_speech_prob": 0.7876471877098083}, {"id": 43, "seek": 54200, "start": 542.0, "end": 549.0, "text": " where the structures diverge the less clear, it is what you're really trying to do.", "tokens": [50364, 689, 264, 9227, 18558, 432, 264, 1570, 1850, 11, 309, 307, 437, 291, 434, 534, 1382, 281, 360, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2920879364013672, "compression_ratio": 1.3688524590163935, "no_speech_prob": 0.930314302444458}, {"id": 44, "seek": 54200, "start": 549.0, "end": 556.0, "text": " So, this alignment, it could be just flat out wrong, depending what you want to do.", "tokens": [50714, 407, 11, 341, 18515, 11, 309, 727, 312, 445, 4962, 484, 2085, 11, 5413, 437, 291, 528, 281, 360, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2920879364013672, "compression_ratio": 1.3688524590163935, "no_speech_prob": 0.930314302444458}, {"id": 45, "seek": 55600, "start": 556.0, "end": 572.0, "text": " In particular, there are, there are some kinds of inferences like phylogenetic trees where it really is very clear that you need homologous residues in the same column but then some other applications, it might not be so, so clear it might be useful", "tokens": [50364, 682, 1729, 11, 456, 366, 11, 456, 366, 512, 3685, 295, 13596, 2667, 411, 903, 88, 4987, 268, 3532, 5852, 689, 309, 534, 307, 588, 1850, 300, 291, 643, 3655, 1132, 563, 13141, 1247, 294, 264, 912, 7738, 457, 550, 512, 661, 5821, 11, 309, 1062, 406, 312, 370, 11, 370, 1850, 309, 1062, 312, 4420, 51164], "temperature": 0.0, "avg_logprob": -0.2892589251200358, "compression_ratio": 1.5276073619631902, "no_speech_prob": 0.7022433280944824}, {"id": 46, "seek": 57200, "start": 572.0, "end": 589.0, "text": " so there's some ambiguity in the alignment. And worst case, this could be really throwing you completely off track if you try to estimate a phylogenetic tree and you give it a region like this, you may just be getting complete nonsense.", "tokens": [50364, 370, 456, 311, 512, 46519, 294, 264, 18515, 13, 400, 5855, 1389, 11, 341, 727, 312, 534, 10238, 291, 2584, 766, 2837, 498, 291, 853, 281, 12539, 257, 903, 88, 4987, 268, 3532, 4230, 293, 291, 976, 309, 257, 4458, 411, 341, 11, 291, 815, 445, 312, 1242, 3566, 14925, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2757966648448597, "compression_ratio": 1.475, "no_speech_prob": 0.37012651562690735}, {"id": 47, "seek": 58900, "start": 589.0, "end": 610.0, "text": " And another thing to keep in mind is that if you, if you sort of represent an alignment like this in a row and column matrix, you're assuming the sort of an implicit assumption that all of the mutations that have happened between the sequences are all mutations", "tokens": [50364, 400, 1071, 551, 281, 1066, 294, 1575, 307, 300, 498, 291, 11, 498, 291, 1333, 295, 2906, 364, 18515, 411, 341, 294, 257, 5386, 293, 7738, 8141, 11, 291, 434, 11926, 264, 1333, 295, 364, 26947, 15302, 300, 439, 295, 264, 29243, 300, 362, 2011, 1296, 264, 22978, 366, 439, 29243, 51414], "temperature": 0.0, "avg_logprob": -0.22329573197798294, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.5886834859848022}, {"id": 48, "seek": 61000, "start": 611.0, "end": 628.0, "text": " or maybe some short insertions and deletions, but there are many other types of mutation that can happen that you simply can't represent in a matrix like that. Well, there can be an inversion which is sort of more something you think about in DNA maybe.", "tokens": [50414, 420, 1310, 512, 2099, 8969, 626, 293, 1103, 302, 626, 11, 457, 456, 366, 867, 661, 3467, 295, 27960, 300, 393, 1051, 300, 291, 2935, 393, 380, 2906, 294, 257, 8141, 411, 300, 13, 1042, 11, 456, 393, 312, 364, 43576, 597, 307, 1333, 295, 544, 746, 291, 519, 466, 294, 8272, 1310, 13, 51264], "temperature": 0.0, "avg_logprob": -0.22545510324938545, "compression_ratio": 1.505952380952381, "no_speech_prob": 0.9171244502067566}, {"id": 49, "seek": 62800, "start": 629.0, "end": 649.0, "text": " I mean, what's the most common short of the sort of the common. Well, what's the most common source of a short insertion, that's hard to say. And that's a short tandem duplication, the most common way that the new letter gets inserted into a protein is you get a little", "tokens": [50414, 286, 914, 11, 437, 311, 264, 881, 2689, 2099, 295, 264, 1333, 295, 264, 2689, 13, 1042, 11, 437, 311, 264, 881, 2689, 4009, 295, 257, 2099, 8969, 313, 11, 300, 311, 1152, 281, 584, 13, 400, 300, 311, 257, 2099, 48120, 17154, 399, 11, 264, 881, 2689, 636, 300, 264, 777, 5063, 2170, 27992, 666, 257, 7944, 307, 291, 483, 257, 707, 51414], "temperature": 0.0, "avg_logprob": -0.3212941582523175, "compression_ratio": 1.7933333333333332, "no_speech_prob": 0.9250602126121521}, {"id": 50, "seek": 64900, "start": 650.0, "end": 667.0, "text": " slippage when the, the gene is duplicated. So these are actually a very common source of mutation, then you've got translocations, and you've got this rather technical thing called the homoplasy and so when you've got distantly related proteins, and you have these more variable", "tokens": [50414, 20129, 609, 562, 264, 11, 264, 12186, 307, 1581, 564, 3587, 13, 407, 613, 366, 767, 257, 588, 2689, 4009, 295, 27960, 11, 550, 291, 600, 658, 1145, 5842, 763, 11, 293, 291, 600, 658, 341, 2831, 6191, 551, 1219, 264, 3655, 404, 7743, 88, 293, 370, 562, 291, 600, 658, 1483, 3627, 4077, 15577, 11, 293, 291, 362, 613, 544, 7006, 51264], "temperature": 0.0, "avg_logprob": -0.2909546187429717, "compression_ratio": 1.6162790697674418, "no_speech_prob": 0.5658760070800781}, {"id": 51, "seek": 66700, "start": 667.0, "end": 685.0, "text": " regions in the loops of the protein, you get insertions, deletions, substitutions, and eventually there's just no residue homology left. And so if the way you should really represent that in a multiple alignment is to have a ton of gaps, but, but alignment", "tokens": [50364, 10682, 294, 264, 16121, 295, 264, 7944, 11, 291, 483, 8969, 626, 11, 1103, 302, 626, 11, 26441, 3666, 11, 293, 4728, 456, 311, 445, 572, 34799, 3655, 1793, 1411, 13, 400, 370, 498, 264, 636, 291, 820, 534, 2906, 300, 294, 257, 3866, 18515, 307, 281, 362, 257, 2952, 295, 15031, 11, 457, 11, 457, 18515, 51264], "temperature": 0.0, "avg_logprob": -0.23465192513387712, "compression_ratio": 1.5609756097560976, "no_speech_prob": 0.4531732499599457}, {"id": 52, "seek": 68500, "start": 686.0, "end": 689.0, "text": " algorithms will never represent it that way.", "tokens": [50414, 14642, 486, 1128, 2906, 309, 300, 636, 13, 50564], "temperature": 0.0, "avg_logprob": -0.24997099240620932, "compression_ratio": 1.3576158940397351, "no_speech_prob": 0.7824087738990784}, {"id": 53, "seek": 68500, "start": 691.0, "end": 702.0, "text": " So I'm going to focus particularly on trees, because it's a very common application of an alignment, and it kind of illustrates the issues I want to talk about.", "tokens": [50664, 407, 286, 478, 516, 281, 1879, 4098, 322, 5852, 11, 570, 309, 311, 257, 588, 2689, 3861, 295, 364, 18515, 11, 293, 309, 733, 295, 41718, 264, 2663, 286, 528, 281, 751, 466, 13, 51214], "temperature": 0.0, "avg_logprob": -0.24997099240620932, "compression_ratio": 1.3576158940397351, "no_speech_prob": 0.7824087738990784}, {"id": 54, "seek": 70200, "start": 702.0, "end": 719.0, "text": " So alignment in itself is not usually the end goal. So the questions you should be asking are not necessarily is alignment in itself, good or bad. The question is, is it good enough to answer the biological question that you're trying to answer.", "tokens": [50364, 407, 18515, 294, 2564, 307, 406, 2673, 264, 917, 3387, 13, 407, 264, 1651, 291, 820, 312, 3365, 366, 406, 4725, 307, 18515, 294, 2564, 11, 665, 420, 1578, 13, 440, 1168, 307, 11, 307, 309, 665, 1547, 281, 1867, 264, 13910, 1168, 300, 291, 434, 1382, 281, 1867, 13, 51214], "temperature": 0.0, "avg_logprob": -0.24034194593076352, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.36274465918540955}, {"id": 55, "seek": 71900, "start": 720.0, "end": 734.0, "text": " And here I'm going to take a concrete example, which is kind of relevant right now, if we're interested in the evolutionary history of COVID, we want to make phylogenetic trees for the coronavirus family.", "tokens": [50414, 400, 510, 286, 478, 516, 281, 747, 257, 9859, 1365, 11, 597, 307, 733, 295, 7340, 558, 586, 11, 498, 321, 434, 3102, 294, 264, 27567, 2503, 295, 4566, 11, 321, 528, 281, 652, 903, 88, 4987, 268, 3532, 5852, 337, 264, 13043, 1605, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2615237622647672, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.6111003160476685}, {"id": 56, "seek": 71900, "start": 735.0, "end": 745.0, "text": " And it's kind of, it's the coronavirus divides quite clearly into four different groups which are called genera.", "tokens": [51164, 400, 309, 311, 733, 295, 11, 309, 311, 264, 13043, 41347, 1596, 4448, 666, 1451, 819, 3935, 597, 366, 1219, 1337, 64, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2615237622647672, "compression_ratio": 1.5023696682464456, "no_speech_prob": 0.6111003160476685}, {"id": 57, "seek": 74500, "start": 745.0, "end": 755.0, "text": " There's just four, that's just kind of the convention in taxonomy. And so I went around the literature and I pulled some, some trees.", "tokens": [50364, 821, 311, 445, 1451, 11, 300, 311, 445, 733, 295, 264, 10286, 294, 3366, 23423, 13, 400, 370, 286, 1437, 926, 264, 10394, 293, 286, 7373, 512, 11, 512, 5852, 13, 50864], "temperature": 0.0, "avg_logprob": -0.26268108912876675, "compression_ratio": 1.2201834862385321, "no_speech_prob": 0.09266103804111481}, {"id": 58, "seek": 75500, "start": 756.0, "end": 773.0, "text": " So ABDG is alpha beta gamma delta here. And you can see that out of six trees I found in the literature, none of them agree with each other, but they all have very high confidence levels.", "tokens": [50414, 407, 13838, 35, 38, 307, 8961, 9861, 15546, 8289, 510, 13, 400, 291, 393, 536, 300, 484, 295, 2309, 5852, 286, 1352, 294, 264, 10394, 11, 6022, 295, 552, 3986, 365, 1184, 661, 11, 457, 436, 439, 362, 588, 1090, 6687, 4358, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24998159611478765, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.3664386570453644}, {"id": 59, "seek": 77300, "start": 773.0, "end": 786.0, "text": " So if you know about phylogenetic trees, the way that you estimate confidence is the same called a bootstrap value and it goes from zero to 100 or from zero to one depending what unit you use.", "tokens": [50364, 407, 498, 291, 458, 466, 903, 88, 4987, 268, 3532, 5852, 11, 264, 636, 300, 291, 12539, 6687, 307, 264, 912, 1219, 257, 11450, 372, 4007, 2158, 293, 309, 1709, 490, 4018, 281, 2319, 420, 490, 4018, 281, 472, 5413, 437, 4985, 291, 764, 13, 51014], "temperature": 0.0, "avg_logprob": -0.255164007122597, "compression_ratio": 1.6160714285714286, "no_speech_prob": 0.25379809737205505}, {"id": 60, "seek": 77300, "start": 787.0, "end": 798.0, "text": " You can see here, all these trees have high confidence, but they disagree with each other. So, at most, one of those trees can be right so something is going wrong here.", "tokens": [51064, 509, 393, 536, 510, 11, 439, 613, 5852, 362, 1090, 6687, 11, 457, 436, 14091, 365, 1184, 661, 13, 407, 11, 412, 881, 11, 472, 295, 729, 5852, 393, 312, 558, 370, 746, 307, 516, 2085, 510, 13, 51614], "temperature": 0.0, "avg_logprob": -0.255164007122597, "compression_ratio": 1.6160714285714286, "no_speech_prob": 0.25379809737205505}, {"id": 61, "seek": 79800, "start": 799.0, "end": 807.0, "text": " So we need to go back and we'll check our assumptions here because the sort of conventional assumptions about how to do this is simply not working.", "tokens": [50414, 407, 321, 643, 281, 352, 646, 293, 321, 603, 1520, 527, 17695, 510, 570, 264, 1333, 295, 16011, 17695, 466, 577, 281, 360, 341, 307, 2935, 406, 1364, 13, 50814], "temperature": 0.0, "avg_logprob": -0.20894254684448244, "compression_ratio": 1.4768211920529801, "no_speech_prob": 0.14028137922286987}, {"id": 62, "seek": 79800, "start": 809.0, "end": 816.0, "text": " And the answer here is that bootstrapping assumes the alignment is correct.", "tokens": [50914, 400, 264, 1867, 510, 307, 300, 11450, 19639, 3759, 37808, 264, 18515, 307, 3006, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20894254684448244, "compression_ratio": 1.4768211920529801, "no_speech_prob": 0.14028137922286987}, {"id": 63, "seek": 81600, "start": 817.0, "end": 823.0, "text": " So typically, you make a tree, you see the high bootstraps, you kind of think okay everything's working okay.", "tokens": [50414, 407, 5850, 11, 291, 652, 257, 4230, 11, 291, 536, 264, 1090, 11450, 19639, 1878, 11, 291, 733, 295, 519, 1392, 1203, 311, 1364, 1392, 13, 50714], "temperature": 0.0, "avg_logprob": -0.25098775780719257, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.2226477861404419}, {"id": 64, "seek": 81600, "start": 824.0, "end": 835.0, "text": " But bootstraps is not a test of whether your alignment is good enough to make the tree, it assumes that the alignment is correct and then asks, is there enough information in the alignment to make the tree.", "tokens": [50764, 583, 11450, 19639, 1878, 307, 406, 257, 1500, 295, 1968, 428, 18515, 307, 665, 1547, 281, 652, 264, 4230, 11, 309, 37808, 300, 264, 18515, 307, 3006, 293, 550, 8962, 11, 307, 456, 1547, 1589, 294, 264, 18515, 281, 652, 264, 4230, 13, 51314], "temperature": 0.0, "avg_logprob": -0.25098775780719257, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.2226477861404419}, {"id": 65, "seek": 81600, "start": 836.0, "end": 840.0, "text": " But if there are systematic errors in the alignment, you have a problem.", "tokens": [51364, 583, 498, 456, 366, 27249, 13603, 294, 264, 18515, 11, 291, 362, 257, 1154, 13, 51564], "temperature": 0.0, "avg_logprob": -0.25098775780719257, "compression_ratio": 1.8262910798122065, "no_speech_prob": 0.2226477861404419}, {"id": 66, "seek": 84000, "start": 841.0, "end": 845.0, "text": " So, what can we do about this.", "tokens": [50414, 407, 11, 437, 393, 321, 360, 466, 341, 13, 50614], "temperature": 0.0, "avg_logprob": -0.27744711450783605, "compression_ratio": 1.6169154228855722, "no_speech_prob": 0.0566466860473156}, {"id": 67, "seek": 84000, "start": 846.0, "end": 857.0, "text": " Well, you know if you're a good biologist you know you're supposed to do replicates of your experiment you try the same experiment, repeat and see just start measuring errors and so on.", "tokens": [50664, 1042, 11, 291, 458, 498, 291, 434, 257, 665, 3228, 9201, 291, 458, 291, 434, 3442, 281, 360, 3248, 299, 1024, 295, 428, 5120, 291, 853, 264, 912, 5120, 11, 7149, 293, 536, 445, 722, 13389, 13603, 293, 370, 322, 13, 51214], "temperature": 0.0, "avg_logprob": -0.27744711450783605, "compression_ratio": 1.6169154228855722, "no_speech_prob": 0.0566466860473156}, {"id": 68, "seek": 84000, "start": 858.0, "end": 864.0, "text": " And you can see we sort of got a model of how we might do this in the literature right here well these guys.", "tokens": [51264, 400, 291, 393, 536, 321, 1333, 295, 658, 257, 2316, 295, 577, 321, 1062, 360, 341, 294, 264, 10394, 558, 510, 731, 613, 1074, 13, 51564], "temperature": 0.0, "avg_logprob": -0.27744711450783605, "compression_ratio": 1.6169154228855722, "no_speech_prob": 0.0566466860473156}, {"id": 69, "seek": 86400, "start": 864.0, "end": 879.0, "text": " Why did they get different trees well they chose a different alignment method and a different tree building software so maybe DeGroote used muscle and Raxomel, maybe Zhu used Maft and QuickTree.", "tokens": [50364, 1545, 630, 436, 483, 819, 5852, 731, 436, 5111, 257, 819, 18515, 3170, 293, 257, 819, 4230, 2390, 4722, 370, 1310, 1346, 38, 340, 1370, 1143, 8679, 293, 497, 2797, 298, 338, 11, 1310, 31680, 1143, 376, 64, 844, 293, 12101, 51, 701, 13, 51114], "temperature": 0.0, "avg_logprob": -0.4074867248535156, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.1259017139673233}, {"id": 70, "seek": 86400, "start": 880.0, "end": 886.0, "text": " And they they came up with different answers so maybe what we should do is we should just like.", "tokens": [51164, 400, 436, 436, 1361, 493, 365, 819, 6338, 370, 1310, 437, 321, 820, 360, 307, 321, 820, 445, 411, 13, 51464], "temperature": 0.0, "avg_logprob": -0.4074867248535156, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.1259017139673233}, {"id": 71, "seek": 88600, "start": 886.0, "end": 892.0, "text": " Do all the try several different ways, ourselves, and see if they give consistent answers.", "tokens": [50364, 1144, 439, 264, 853, 2940, 819, 2098, 11, 4175, 11, 293, 536, 498, 436, 976, 8398, 6338, 13, 50664], "temperature": 0.0, "avg_logprob": -0.28888236908685594, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.23646657168865204}, {"id": 72, "seek": 88600, "start": 894.0, "end": 913.0, "text": " Now people are people essentially never do that. And so, why not, then I think the answer to that is that people generally they've got some idea about well what's the best method because there's a benchmark test out there, or because their friend told them that's how they do it.", "tokens": [50764, 823, 561, 366, 561, 4476, 1128, 360, 300, 13, 400, 370, 11, 983, 406, 11, 550, 286, 519, 264, 1867, 281, 300, 307, 300, 561, 5101, 436, 600, 658, 512, 1558, 466, 731, 437, 311, 264, 1151, 3170, 570, 456, 311, 257, 18927, 1500, 484, 456, 11, 420, 570, 641, 1277, 1907, 552, 300, 311, 577, 436, 360, 309, 13, 51714], "temperature": 0.0, "avg_logprob": -0.28888236908685594, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.23646657168865204}, {"id": 73, "seek": 91300, "start": 913.0, "end": 924.0, "text": " And they think the friend is more expert than they are. So there's sort of this general perception that there's one way that's the best or shown to be the best or I'm just going to work with it.", "tokens": [50364, 400, 436, 519, 264, 1277, 307, 544, 5844, 813, 436, 366, 13, 407, 456, 311, 1333, 295, 341, 2674, 12860, 300, 456, 311, 472, 636, 300, 311, 264, 1151, 420, 4898, 281, 312, 264, 1151, 420, 286, 478, 445, 516, 281, 589, 365, 309, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2872932928579825, "compression_ratio": 1.5036496350364963, "no_speech_prob": 0.19924239814281464}, {"id": 74, "seek": 91300, "start": 925.0, "end": 926.0, "text": " And there's", "tokens": [50964, 400, 456, 311, 51014], "temperature": 0.0, "avg_logprob": -0.2872932928579825, "compression_ratio": 1.5036496350364963, "no_speech_prob": 0.19924239814281464}, {"id": 75, "seek": 92600, "start": 927.0, "end": 939.0, "text": " sort of a concern that if you use some other method that's not quite as good as the best method, then well you discount the fact that that method disagrees, and you just trust the best one.", "tokens": [50414, 1333, 295, 257, 3136, 300, 498, 291, 764, 512, 661, 3170, 300, 311, 406, 1596, 382, 665, 382, 264, 1151, 3170, 11, 550, 731, 291, 11635, 264, 1186, 300, 300, 3170, 10414, 4856, 11, 293, 291, 445, 3361, 264, 1151, 472, 13, 51014], "temperature": 0.0, "avg_logprob": -0.262281376382579, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.38483718037605286}, {"id": 76, "seek": 93900, "start": 940.0, "end": 948.0, "text": " So, I don't know, there's whatever the psychological sociological reason this is almost never done, but this example shows that maybe people should be doing this.", "tokens": [50414, 407, 11, 286, 500, 380, 458, 11, 456, 311, 2035, 264, 14346, 3075, 4383, 1778, 341, 307, 1920, 1128, 1096, 11, 457, 341, 1365, 3110, 300, 1310, 561, 820, 312, 884, 341, 13, 50814], "temperature": 0.0, "avg_logprob": -0.4276976994105748, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.14407075941562653}, {"id": 77, "seek": 93900, "start": 950.0, "end": 960.0, "text": " So, this gives me sort of the motivation for the essentially new ideas that are in muscle five, which is, well, how can we do this.", "tokens": [50914, 407, 11, 341, 2709, 385, 1333, 295, 264, 12335, 337, 264, 4476, 777, 3487, 300, 366, 294, 8679, 1732, 11, 597, 307, 11, 731, 11, 577, 393, 321, 360, 341, 13, 51414], "temperature": 0.0, "avg_logprob": -0.4276976994105748, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.14407075941562653}, {"id": 78, "seek": 96000, "start": 961.0, "end": 967.0, "text": " So if you remember back to the opening slides when we, when a computer makes an alignment.", "tokens": [50414, 407, 498, 291, 1604, 646, 281, 264, 5193, 9788, 562, 321, 11, 562, 257, 3820, 1669, 364, 18515, 13, 50714], "temperature": 0.0, "avg_logprob": -0.46537896861200745, "compression_ratio": 1.0975609756097562, "no_speech_prob": 0.13472245633602142}, {"id": 79, "seek": 96700, "start": 968.0, "end": 976.0, "text": " It's based on this very, very simple model where we have a substitution matrix, and typically a couple of lines.", "tokens": [50414, 467, 311, 2361, 322, 341, 588, 11, 588, 2199, 2316, 689, 321, 362, 257, 35827, 8141, 11, 293, 5850, 257, 1916, 295, 3876, 13, 50814], "temperature": 0.0, "avg_logprob": -0.5067599160330636, "compression_ratio": 1.1428571428571428, "no_speech_prob": 0.3701166808605194}, {"id": 80, "seek": 97600, "start": 977.0, "end": 978.0, "text": " Excuse me.", "tokens": [50414, 11359, 385, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2779082545527705, "compression_ratio": 1.3726708074534162, "no_speech_prob": 0.250711590051651}, {"id": 81, "seek": 97600, "start": 983.0, "end": 998.0, "text": " So if you remember back to the opening slides when we, when a computer makes an alignment. It's based on this very, very simple model where we have a substitution matrix and typically a couple of gap penalties.", "tokens": [50714, 407, 498, 291, 1604, 646, 281, 264, 5193, 9788, 562, 321, 11, 562, 257, 3820, 1669, 364, 18515, 13, 467, 311, 2361, 322, 341, 588, 11, 588, 2199, 2316, 689, 321, 362, 257, 35827, 8141, 293, 5850, 257, 1916, 295, 7417, 3435, 3198, 530, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2779082545527705, "compression_ratio": 1.3726708074534162, "no_speech_prob": 0.250711590051651}, {"id": 82, "seek": 99800, "start": 999.0, "end": 1014.0, "text": " And you take the how do you set those parameters well you measure them on some benchmark and then you set the default values for those parameters, based on whatever comes out best on the benchmark.", "tokens": [50414, 400, 291, 747, 264, 577, 360, 291, 992, 729, 9834, 731, 291, 3481, 552, 322, 512, 18927, 293, 550, 291, 992, 264, 7576, 4190, 337, 729, 9834, 11, 2361, 322, 2035, 1487, 484, 1151, 322, 264, 18927, 13, 51164], "temperature": 0.0, "avg_logprob": -0.26036653064546134, "compression_ratio": 1.576, "no_speech_prob": 0.31063058972358704}, {"id": 83, "seek": 101400, "start": 1015.0, "end": 1038.0, "text": " But if you think about it, they're kind of right round numbers and averaged over benchmark so should they really matter whether you use five or 5.1 or two or 1.9 for your gap penalties and the answer really, it shouldn't matter if it does, then you should start to be suspicious that your results are any good.", "tokens": [50414, 583, 498, 291, 519, 466, 309, 11, 436, 434, 733, 295, 558, 3098, 3547, 293, 18247, 2980, 670, 18927, 370, 820, 436, 534, 1871, 1968, 291, 764, 1732, 420, 1025, 13, 16, 420, 732, 420, 502, 13, 24, 337, 428, 7417, 3435, 3198, 530, 293, 264, 1867, 534, 11, 309, 4659, 380, 1871, 498, 309, 775, 11, 550, 291, 820, 722, 281, 312, 17931, 300, 428, 3542, 366, 604, 665, 13, 51564], "temperature": 0.0, "avg_logprob": -0.307745361328125, "compression_ratio": 1.5736040609137056, "no_speech_prob": 0.24790121614933014}, {"id": 84, "seek": 103800, "start": 1039.0, "end": 1050.0, "text": " So the idea is to do what I call perturbing parameters, so we introduced some small random variations for example into the back into the gap penalties.", "tokens": [50414, 407, 264, 1558, 307, 281, 360, 437, 286, 818, 13269, 374, 4324, 9834, 11, 370, 321, 7268, 512, 1359, 4974, 17840, 337, 1365, 666, 264, 646, 666, 264, 7417, 35389, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2745845128619482, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.1365470290184021}, {"id": 85, "seek": 103800, "start": 1050.0, "end": 1058.0, "text": " And we asked, does that change the alignment, and does that change the downstream analysis that you're doing, such as trees.", "tokens": [50964, 400, 321, 2351, 11, 775, 300, 1319, 264, 18515, 11, 293, 775, 300, 1319, 264, 30621, 5215, 300, 291, 434, 884, 11, 1270, 382, 5852, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2745845128619482, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.1365470290184021}, {"id": 86, "seek": 105800, "start": 1059.0, "end": 1072.0, "text": " And, well, how, how do you set the scale for these perturbations and the, the standard. Well, how did we come up with them in the first place we we tuned them on some benchmark test.", "tokens": [50414, 400, 11, 731, 11, 577, 11, 577, 360, 291, 992, 264, 4373, 337, 613, 40468, 763, 293, 264, 11, 264, 3832, 13, 1042, 11, 577, 630, 321, 808, 493, 365, 552, 294, 264, 700, 1081, 321, 321, 10870, 552, 322, 512, 18927, 1500, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2794356672731164, "compression_ratio": 1.620879120879121, "no_speech_prob": 0.31059542298316956}, {"id": 87, "seek": 105800, "start": 1072.0, "end": 1080.0, "text": " And the standard should be that we make them as large as possible because we want replicates that are different.", "tokens": [51064, 400, 264, 3832, 820, 312, 300, 321, 652, 552, 382, 2416, 382, 1944, 570, 321, 528, 3248, 299, 1024, 300, 366, 819, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2794356672731164, "compression_ratio": 1.620879120879121, "no_speech_prob": 0.31059542298316956}, {"id": 88, "seek": 108000, "start": 1080.0, "end": 1090.0, "text": " But we don't want to degrade the accuracy, accuracy on our benchmark because once you start to degrade accuracy, people are not going to use your method.", "tokens": [50364, 583, 321, 500, 380, 528, 281, 368, 8692, 264, 14170, 11, 14170, 322, 527, 18927, 570, 1564, 291, 722, 281, 368, 8692, 14170, 11, 561, 366, 406, 516, 281, 764, 428, 3170, 13, 50864], "temperature": 0.0, "avg_logprob": -0.26192520459493, "compression_ratio": 1.579268292682927, "no_speech_prob": 0.4415232241153717}, {"id": 89, "seek": 108000, "start": 1090.0, "end": 1098.0, "text": " So you want to be in that sweet spot where you maximize the variation without paying a price in accuracy.", "tokens": [50864, 407, 291, 528, 281, 312, 294, 300, 3844, 4008, 689, 291, 19874, 264, 12990, 1553, 6229, 257, 3218, 294, 14170, 13, 51264], "temperature": 0.0, "avg_logprob": -0.26192520459493, "compression_ratio": 1.579268292682927, "no_speech_prob": 0.4415232241153717}, {"id": 90, "seek": 109800, "start": 1098.0, "end": 1113.0, "text": " Okay, so I promised a gentle introduction so we're going to have a couple of slides here which are not gentle at all but we'll quickly go back to, to more gentle presentation but so how do I actually do that.", "tokens": [50364, 1033, 11, 370, 286, 10768, 257, 6424, 9339, 370, 321, 434, 516, 281, 362, 257, 1916, 295, 9788, 510, 597, 366, 406, 6424, 412, 439, 457, 321, 603, 2661, 352, 646, 281, 11, 281, 544, 6424, 5860, 457, 370, 577, 360, 286, 767, 360, 300, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2668170547485352, "compression_ratio": 1.4149659863945578, "no_speech_prob": 0.11918405443429947}, {"id": 91, "seek": 111300, "start": 1114.0, "end": 1122.0, "text": " And the, the, this is okay so this is all kind of mathematical it's based on a thing called a hidden markup model.", "tokens": [50414, 400, 264, 11, 264, 11, 341, 307, 1392, 370, 341, 307, 439, 733, 295, 18894, 309, 311, 2361, 322, 257, 551, 1219, 257, 7633, 1491, 1010, 2316, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2695228313577586, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.49208974838256836}, {"id": 92, "seek": 111300, "start": 1122.0, "end": 1141.0, "text": " And this was introduced by by a group from Stanford, way back in 2005 around about the same time that I was doing the first version of muscle, and it's a very, from a mathematical point of view it's a very elegant framework where everything is probabilities.", "tokens": [50814, 400, 341, 390, 7268, 538, 538, 257, 1594, 490, 20374, 11, 636, 646, 294, 14394, 926, 466, 264, 912, 565, 300, 286, 390, 884, 264, 700, 3037, 295, 8679, 11, 293, 309, 311, 257, 588, 11, 490, 257, 18894, 935, 295, 1910, 309, 311, 257, 588, 21117, 8388, 689, 1203, 307, 33783, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2695228313577586, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.49208974838256836}, {"id": 93, "seek": 114100, "start": 1142.0, "end": 1160.0, "text": " But really it's just, it's nothing fancier from an evolutionary point of view is it's basically just this very simplified model where you have a substitution matrix gap penalties here you actually have four instead of two, but you know it's not that different.", "tokens": [50414, 583, 534, 309, 311, 445, 11, 309, 311, 1825, 3429, 27674, 490, 364, 27567, 935, 295, 1910, 307, 309, 311, 1936, 445, 341, 588, 26335, 2316, 689, 291, 362, 257, 35827, 8141, 7417, 3435, 3198, 530, 510, 291, 767, 362, 1451, 2602, 295, 732, 11, 457, 291, 458, 309, 311, 406, 300, 819, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2614282575146905, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.07157058268785477}, {"id": 94, "seek": 116000, "start": 1161.0, "end": 1179.0, "text": " And so this gives me a nice little way where I can introduce random perturbations in a sort of a principle way and keep everything under control and not just doing sort of arbitrary things.", "tokens": [50414, 400, 370, 341, 2709, 385, 257, 1481, 707, 636, 689, 286, 393, 5366, 4974, 40468, 763, 294, 257, 1333, 295, 257, 8665, 636, 293, 1066, 1203, 833, 1969, 293, 406, 445, 884, 1333, 295, 23211, 721, 13, 51314], "temperature": 0.0, "avg_logprob": -0.22431395270607687, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.27507489919662476}, {"id": 95, "seek": 116000, "start": 1179.0, "end": 1183.0, "text": " And", "tokens": [51314, 400, 51514], "temperature": 0.0, "avg_logprob": -0.22431395270607687, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.27507489919662476}, {"id": 96, "seek": 118300, "start": 1184.0, "end": 1191.0, "text": " this is how muscle five works okay so that's everything I basically just said.", "tokens": [50414, 341, 307, 577, 8679, 1732, 1985, 1392, 370, 300, 311, 1203, 286, 1936, 445, 848, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24714538029261998, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.45319393277168274}, {"id": 97, "seek": 118300, "start": 1191.0, "end": 1196.0, "text": " So now the idea is instead of just running one alignment.", "tokens": [50764, 407, 586, 264, 1558, 307, 2602, 295, 445, 2614, 472, 18515, 13, 51014], "temperature": 0.0, "avg_logprob": -0.24714538029261998, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.45319393277168274}, {"id": 98, "seek": 118300, "start": 1196.0, "end": 1207.0, "text": " We run a whole set of replicates that's what I call the ensemble, so we just keep changing the parameters, a little bit, making a different alignment.", "tokens": [51014, 492, 1190, 257, 1379, 992, 295, 3248, 299, 1024, 300, 311, 437, 286, 818, 264, 19492, 11, 370, 321, 445, 1066, 4473, 264, 9834, 11, 257, 707, 857, 11, 1455, 257, 819, 18515, 13, 51564], "temperature": 0.0, "avg_logprob": -0.24714538029261998, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.45319393277168274}, {"id": 99, "seek": 120700, "start": 1208.0, "end": 1220.0, "text": " And if we see that the alignment is the same every time, this gives us a lot more confidence that the alignment is correct because it's robust against these changes in the model which really shouldn't matter.", "tokens": [50414, 400, 498, 321, 536, 300, 264, 18515, 307, 264, 912, 633, 565, 11, 341, 2709, 505, 257, 688, 544, 6687, 300, 264, 18515, 307, 3006, 570, 309, 311, 13956, 1970, 613, 2962, 294, 264, 2316, 597, 534, 4659, 380, 1871, 13, 51014], "temperature": 0.0, "avg_logprob": -0.19529256702941142, "compression_ratio": 1.738938053097345, "no_speech_prob": 0.4998502731323242}, {"id": 100, "seek": 120700, "start": 1220.0, "end": 1234.0, "text": " And you can focus on individual columns, maybe some columns are consistently reproduced and some are less so you can actually assign a confidence level to each column in the alignment.", "tokens": [51014, 400, 291, 393, 1879, 322, 2609, 13766, 11, 1310, 512, 13766, 366, 14961, 11408, 1232, 293, 512, 366, 1570, 370, 291, 393, 767, 6269, 257, 6687, 1496, 281, 1184, 7738, 294, 264, 18515, 13, 51714], "temperature": 0.0, "avg_logprob": -0.19529256702941142, "compression_ratio": 1.738938053097345, "no_speech_prob": 0.4998502731323242}, {"id": 101, "seek": 123400, "start": 1234.0, "end": 1248.0, "text": " And then even if the alignment barriers that doesn't necessarily mean that's bad, it may still be good enough for a given purpose so what you should do is well you continue the analysis and you estimate your tree.", "tokens": [50364, 400, 550, 754, 498, 264, 18515, 13565, 300, 1177, 380, 4725, 914, 300, 311, 1578, 11, 309, 815, 920, 312, 665, 1547, 337, 257, 2212, 4334, 370, 437, 291, 820, 360, 307, 731, 291, 2354, 264, 5215, 293, 291, 12539, 428, 4230, 13, 51064], "temperature": 0.0, "avg_logprob": -0.22400170878360146, "compression_ratio": 1.6336633663366336, "no_speech_prob": 0.0900752916932106}, {"id": 102, "seek": 123400, "start": 1248.0, "end": 1257.0, "text": " And you can not only can you see if the tree is consistent, but you can see if the bootstrap values are trustworthy.", "tokens": [51064, 400, 291, 393, 406, 787, 393, 291, 536, 498, 264, 4230, 307, 8398, 11, 457, 291, 393, 536, 498, 264, 11450, 372, 4007, 4190, 366, 39714, 13, 51514], "temperature": 0.0, "avg_logprob": -0.22400170878360146, "compression_ratio": 1.6336633663366336, "no_speech_prob": 0.0900752916932106}, {"id": 103, "seek": 125700, "start": 1257.0, "end": 1278.0, "text": " Because if the trees come out different but with high bootstraps, then you should not trust the bootstraps you should believe the ensemble of trees is telling you which is that some parts of the tree are not reproducible, so it gives you a different way of approaching this whole sort of pipeline.", "tokens": [50364, 1436, 498, 264, 5852, 808, 484, 819, 457, 365, 1090, 11450, 19639, 1878, 11, 550, 291, 820, 406, 3361, 264, 11450, 19639, 1878, 291, 820, 1697, 264, 19492, 295, 5852, 307, 3585, 291, 597, 307, 300, 512, 3166, 295, 264, 4230, 366, 406, 11408, 32128, 11, 370, 309, 2709, 291, 257, 819, 636, 295, 14908, 341, 1379, 1333, 295, 15517, 13, 51414], "temperature": 0.0, "avg_logprob": -0.23728790283203124, "compression_ratio": 1.737327188940092, "no_speech_prob": 0.08880597352981567}, {"id": 104, "seek": 125700, "start": 1278.0, "end": 1285.0, "text": " So now I need to sort of digress into another sort of technical issue which is.", "tokens": [51414, 407, 586, 286, 643, 281, 1333, 295, 2528, 735, 666, 1071, 1333, 295, 6191, 2734, 597, 307, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23728790283203124, "compression_ratio": 1.737327188940092, "no_speech_prob": 0.08880597352981567}, {"id": 105, "seek": 128500, "start": 1285.0, "end": 1291.0, "text": " Well, the hidden markup model or blast or whatever that's how you align two sequences.", "tokens": [50364, 1042, 11, 264, 7633, 1491, 1010, 2316, 420, 12035, 420, 2035, 300, 311, 577, 291, 7975, 732, 22978, 13, 50664], "temperature": 0.0, "avg_logprob": -0.3821067810058594, "compression_ratio": 1.4052287581699345, "no_speech_prob": 0.45701122283935547}, {"id": 106, "seek": 128500, "start": 1291.0, "end": 1302.0, "text": " But how do you build a multiple alignment, and the answer is, essentially every popular method, there is muscle prop cones math.", "tokens": [50664, 583, 577, 360, 291, 1322, 257, 3866, 18515, 11, 293, 264, 1867, 307, 11, 4476, 633, 3743, 3170, 11, 456, 307, 8679, 2365, 40548, 5221, 13, 51214], "temperature": 0.0, "avg_logprob": -0.3821067810058594, "compression_ratio": 1.4052287581699345, "no_speech_prob": 0.45701122283935547}, {"id": 107, "seek": 130200, "start": 1302.0, "end": 1322.0, "text": " They all assemble the final alignment, using the strategy which is called progressive alignment, and the way that this works is you at every step you do a pairwise alignment, and when you start at the very beginning at the bottom of the tree you have individual", "tokens": [50364, 814, 439, 22364, 264, 2572, 18515, 11, 1228, 264, 5206, 597, 307, 1219, 16131, 18515, 11, 293, 264, 636, 300, 341, 1985, 307, 291, 412, 633, 1823, 291, 360, 257, 6119, 3711, 18515, 11, 293, 562, 291, 722, 412, 264, 588, 2863, 412, 264, 2767, 295, 264, 4230, 291, 362, 2609, 51364], "temperature": 0.0, "avg_logprob": -0.24535063038701596, "compression_ratio": 1.6577540106951871, "no_speech_prob": 0.30730247497558594}, {"id": 108, "seek": 130200, "start": 1322.0, "end": 1327.0, "text": " sequences. And as you work your way up the tree.", "tokens": [51364, 22978, 13, 400, 382, 291, 589, 428, 636, 493, 264, 4230, 13, 51614], "temperature": 0.0, "avg_logprob": -0.24535063038701596, "compression_ratio": 1.6577540106951871, "no_speech_prob": 0.30730247497558594}, {"id": 109, "seek": 132700, "start": 1327.0, "end": 1329.0, "text": " You have.", "tokens": [50364, 509, 362, 13, 50464], "temperature": 0.0, "avg_logprob": -0.25725774622675196, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.880699098110199}, {"id": 110, "seek": 132700, "start": 1329.0, "end": 1345.0, "text": " So let's say at the first node, now you have a pair of sequences align, while you keep them aligned to each other, and you align them to something else so at each stage you keep the alignments intact and you have a pairwise alignments of the two alignments.", "tokens": [50464, 407, 718, 311, 584, 412, 264, 700, 9984, 11, 586, 291, 362, 257, 6119, 295, 22978, 7975, 11, 1339, 291, 1066, 552, 17962, 281, 1184, 661, 11, 293, 291, 7975, 552, 281, 746, 1646, 370, 412, 1184, 3233, 291, 1066, 264, 7975, 1117, 23493, 293, 291, 362, 257, 6119, 3711, 7975, 1117, 295, 264, 732, 7975, 1117, 13, 51264], "temperature": 0.0, "avg_logprob": -0.25725774622675196, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.880699098110199}, {"id": 111, "seek": 134500, "start": 1345.0, "end": 1355.0, "text": " And this, this process can be could be regarded as a tree or following a binary tree and that tree is called the guide tree.", "tokens": [50364, 400, 341, 11, 341, 1399, 393, 312, 727, 312, 26047, 382, 257, 4230, 420, 3480, 257, 17434, 4230, 293, 300, 4230, 307, 1219, 264, 5934, 4230, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2504999796549479, "compression_ratio": 1.6, "no_speech_prob": 0.4376714527606964}, {"id": 112, "seek": 134500, "start": 1355.0, "end": 1372.0, "text": " Sometimes it's explicitly constructed beginning sometimes you sort of dynamically figure out which pair, you're going to join at each iteration but the bottom line is there's always a guide tree of one kind or another involved.", "tokens": [50864, 4803, 309, 311, 20803, 17083, 2863, 2171, 291, 1333, 295, 43492, 2573, 484, 597, 6119, 11, 291, 434, 516, 281, 3917, 412, 1184, 24784, 457, 264, 2767, 1622, 307, 456, 311, 1009, 257, 5934, 4230, 295, 472, 733, 420, 1071, 3288, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2504999796549479, "compression_ratio": 1.6, "no_speech_prob": 0.4376714527606964}, {"id": 113, "seek": 137200, "start": 1372.0, "end": 1381.0, "text": " And this is a problem for phylogenetics because well if you have a more challenging alignment.", "tokens": [50364, 400, 341, 307, 257, 1154, 337, 903, 88, 4987, 268, 15793, 570, 731, 498, 291, 362, 257, 544, 7595, 18515, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2028781817509578, "compression_ratio": 1.4350649350649352, "no_speech_prob": 0.04671801999211311}, {"id": 114, "seek": 137200, "start": 1381.0, "end": 1393.0, "text": " Every time you make one of these joins the quality goes down, you have fewer and fewer correct columns or good enough columns.", "tokens": [50814, 2048, 565, 291, 652, 472, 295, 613, 24397, 264, 3125, 1709, 760, 11, 291, 362, 13366, 293, 13366, 3006, 13766, 420, 665, 1547, 13766, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2028781817509578, "compression_ratio": 1.4350649350649352, "no_speech_prob": 0.04671801999211311}, {"id": 115, "seek": 139300, "start": 1394.0, "end": 1407.0, "text": " So it means that the sort of the systematic errors the pattern of good columns well conserved columns and errors in the final tree reflects the guide tree that you use to build it.", "tokens": [50414, 407, 309, 1355, 300, 264, 1333, 295, 264, 27249, 13603, 264, 5102, 295, 665, 13766, 731, 1014, 6913, 13766, 293, 13603, 294, 264, 2572, 4230, 18926, 264, 5934, 4230, 300, 291, 764, 281, 1322, 309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2953378503972834, "compression_ratio": 1.6965174129353233, "no_speech_prob": 0.6618363261222839}, {"id": 116, "seek": 139300, "start": 1407.0, "end": 1413.0, "text": " So if you then take that alignment and you give it to RaxML or quick tree or whatever.", "tokens": [51064, 407, 498, 291, 550, 747, 300, 18515, 293, 291, 976, 309, 281, 497, 2797, 12683, 420, 1702, 4230, 420, 2035, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2953378503972834, "compression_ratio": 1.6965174129353233, "no_speech_prob": 0.6618363261222839}, {"id": 117, "seek": 139300, "start": 1413.0, "end": 1419.0, "text": " Those systematic errors can get reflected in the maximum likelihood tree.", "tokens": [51364, 3950, 27249, 13603, 393, 483, 15502, 294, 264, 6674, 22119, 4230, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2953378503972834, "compression_ratio": 1.6965174129353233, "no_speech_prob": 0.6618363261222839}, {"id": 118, "seek": 141900, "start": 1419.0, "end": 1435.0, "text": " So well how does that bootstrapping actually work for bootstrapping takes a sort of a random samples from the columns in your alignment and asks whether that subsample reproduces the same tree or not.", "tokens": [50364, 407, 731, 577, 775, 300, 11450, 19639, 3759, 767, 589, 337, 11450, 19639, 3759, 2516, 257, 1333, 295, 257, 4974, 10938, 490, 264, 13766, 294, 428, 18515, 293, 8962, 1968, 300, 2090, 335, 781, 11408, 887, 264, 912, 4230, 420, 406, 13, 51164], "temperature": 0.0, "avg_logprob": -0.25636666754017706, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.23929646611213684}, {"id": 119, "seek": 143500, "start": 1435.0, "end": 1456.0, "text": " If you have systematic errors, then you can have the same patterns of this sort of underlying guide tree reproduced in different columns, and this is the mechanism where systematic errors in the alignment can produce systematic errors in the tree, and can give you spuriously high bootstrap values.", "tokens": [50364, 759, 291, 362, 27249, 13603, 11, 550, 291, 393, 362, 264, 912, 8294, 295, 341, 1333, 295, 14217, 5934, 4230, 11408, 1232, 294, 819, 13766, 11, 293, 341, 307, 264, 7513, 689, 27249, 13603, 294, 264, 18515, 393, 5258, 27249, 13603, 294, 264, 4230, 11, 293, 393, 976, 291, 637, 24274, 356, 1090, 11450, 372, 4007, 4190, 13, 51414], "temperature": 0.0, "avg_logprob": -0.24039882503143728, "compression_ratio": 1.690721649484536, "no_speech_prob": 0.14803019165992737}, {"id": 120, "seek": 143500, "start": 1456.0, "end": 1463.0, "text": " So, this is what I just said.", "tokens": [51414, 407, 11, 341, 307, 437, 286, 445, 848, 13, 51764], "temperature": 0.0, "avg_logprob": -0.24039882503143728, "compression_ratio": 1.690721649484536, "no_speech_prob": 0.14803019165992737}, {"id": 121, "seek": 146300, "start": 1463.0, "end": 1477.0, "text": " So muscle five does something else. It doesn't just perturb the HMM parameters. It also makes variations in this guide tree.", "tokens": [50364, 407, 8679, 1732, 775, 746, 1646, 13, 467, 1177, 380, 445, 40468, 264, 389, 17365, 9834, 13, 467, 611, 1669, 17840, 294, 341, 5934, 4230, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20910201602511935, "compression_ratio": 1.3237410071942446, "no_speech_prob": 0.19433729350566864}, {"id": 122, "seek": 146300, "start": 1477.0, "end": 1484.0, "text": " And you have to do this in a rather carefully designed way.", "tokens": [51064, 400, 291, 362, 281, 360, 341, 294, 257, 2831, 7500, 4761, 636, 13, 51414], "temperature": 0.0, "avg_logprob": -0.20910201602511935, "compression_ratio": 1.3237410071942446, "no_speech_prob": 0.19433729350566864}, {"id": 123, "seek": 148400, "start": 1485.0, "end": 1504.0, "text": " Because you sort of have conflicting goals. So one of the reasons you have a guide tree is that you get the most accurate alignment, when you align the most closely related sequences so if you just take two groups of random and align them they might be more", "tokens": [50414, 1436, 291, 1333, 295, 362, 43784, 5493, 13, 407, 472, 295, 264, 4112, 291, 362, 257, 5934, 4230, 307, 300, 291, 483, 264, 881, 8559, 18515, 11, 562, 291, 7975, 264, 881, 8185, 4077, 22978, 370, 498, 291, 445, 747, 732, 3935, 295, 4974, 293, 7975, 552, 436, 1062, 312, 544, 51364], "temperature": 0.0, "avg_logprob": -0.2623768372969194, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.7771334052085876}, {"id": 124, "seek": 150400, "start": 1504.0, "end": 1508.0, "text": " closely related and you're writing errors more quickly.", "tokens": [50364, 8185, 4077, 293, 291, 434, 3579, 13603, 544, 2661, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2527670383453369, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.6891374588012695}, {"id": 125, "seek": 150400, "start": 1508.0, "end": 1519.0, "text": " So you every step you want to get something close to the most closely related groups in order to get the highest accuracy.", "tokens": [50564, 407, 291, 633, 1823, 291, 528, 281, 483, 746, 1998, 281, 264, 881, 8185, 4077, 3935, 294, 1668, 281, 483, 264, 6343, 14170, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2527670383453369, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.6891374588012695}, {"id": 126, "seek": 151900, "start": 1519.0, "end": 1538.0, "text": " You also want to vary this tree in a meaningful way so that it has a chance to sort of expose the systematic errors. So, the way that muscle five does this is that it preserves the guide tree close to the leaves, but as you get close to the final alignment", "tokens": [50364, 509, 611, 528, 281, 10559, 341, 4230, 294, 257, 10995, 636, 370, 300, 309, 575, 257, 2931, 281, 1333, 295, 19219, 264, 27249, 13603, 13, 407, 11, 264, 636, 300, 8679, 1732, 775, 341, 307, 300, 309, 1183, 9054, 264, 5934, 4230, 1998, 281, 264, 5510, 11, 457, 382, 291, 483, 1998, 281, 264, 2572, 18515, 51314], "temperature": 0.0, "avg_logprob": -0.2463741620381673, "compression_ratio": 1.5609756097560976, "no_speech_prob": 0.456853985786438}, {"id": 127, "seek": 153800, "start": 1538.0, "end": 1559.0, "text": " so the last two or three joins, it switches around the order. So, it does. So this is sort of the notation that I use. And there's four variants like this for the final assembly stage of the multiple alignment.", "tokens": [50364, 370, 264, 1036, 732, 420, 1045, 24397, 11, 309, 19458, 926, 264, 1668, 13, 407, 11, 309, 775, 13, 407, 341, 307, 1333, 295, 264, 24657, 300, 286, 764, 13, 400, 456, 311, 1451, 21669, 411, 341, 337, 264, 2572, 12103, 3233, 295, 264, 3866, 18515, 13, 51414], "temperature": 0.0, "avg_logprob": -0.23807714499679267, "compression_ratio": 1.4482758620689655, "no_speech_prob": 0.5076207518577576}, {"id": 128, "seek": 155900, "start": 1560.0, "end": 1575.0, "text": " So now, the ways that replicates are generated it's a combination of a perturbation of the HMM parameters and this joining order of the tree.", "tokens": [50414, 407, 586, 11, 264, 2098, 300, 3248, 299, 1024, 366, 10833, 309, 311, 257, 6562, 295, 257, 40468, 399, 295, 264, 389, 17365, 9834, 293, 341, 5549, 1668, 295, 264, 4230, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2018956078423394, "compression_ratio": 1.2818181818181817, "no_speech_prob": 0.7877048850059509}, {"id": 129, "seek": 157500, "start": 1575.0, "end": 1596.0, "text": " So now to some benchmark results. So, the sort of gold standard in protein multiple alignment is this benchmark set called barley base, and it's worth noting that the best sequence, the best alignment methods, and here I'm showing", "tokens": [50364, 407, 586, 281, 512, 18927, 3542, 13, 407, 11, 264, 1333, 295, 3821, 3832, 294, 7944, 3866, 18515, 307, 341, 18927, 992, 1219, 47761, 3096, 11, 293, 309, 311, 3163, 26801, 300, 264, 1151, 8310, 11, 264, 1151, 18515, 7150, 11, 293, 510, 286, 478, 4099, 51414], "temperature": 0.0, "avg_logprob": -0.2956328201293945, "compression_ratio": 1.5032679738562091, "no_speech_prob": 0.3449622392654419}, {"id": 130, "seek": 159600, "start": 1597.0, "end": 1611.0, "text": " you know there's a few other competitors but those are definitely among the state-of-the-art. But you'll notice that the left is the y-axis and that's the fraction of columns that are correctly aligned on this set.", "tokens": [50414, 291, 458, 456, 311, 257, 1326, 661, 18333, 457, 729, 366, 2138, 3654, 264, 1785, 12, 2670, 12, 3322, 12, 446, 13, 583, 291, 603, 3449, 300, 264, 1411, 307, 264, 288, 12, 24633, 293, 300, 311, 264, 14135, 295, 13766, 300, 366, 8944, 17962, 322, 341, 992, 13, 51114], "temperature": 0.0, "avg_logprob": -0.3119176468759213, "compression_ratio": 1.445945945945946, "no_speech_prob": 0.9016765356063843}, {"id": 131, "seek": 161100, "start": 1611.0, "end": 1627.0, "text": " And we're only in sort of the 50 to 60% range. So, this tells you that there is a lot of uncertainty and even the best methods don't reproduce structural alignments on this benchmark.", "tokens": [50364, 400, 321, 434, 787, 294, 1333, 295, 264, 2625, 281, 4060, 4, 3613, 13, 407, 11, 341, 5112, 291, 300, 456, 307, 257, 688, 295, 15697, 293, 754, 264, 1151, 7150, 500, 380, 29501, 15067, 7975, 1117, 322, 341, 18927, 13, 51164], "temperature": 0.0, "avg_logprob": -0.22059620751274955, "compression_ratio": 1.326086956521739, "no_speech_prob": 0.5619848966598511}, {"id": 132, "seek": 162700, "start": 1628.0, "end": 1643.0, "text": " But there are sort of two lessons here I want to sort of draw out on this slide. One is, well, muscle 5 is slightly better than the competition here. I mean, I don't think it's better in any meaningful way, to be honest.", "tokens": [50414, 583, 456, 366, 1333, 295, 732, 8820, 510, 286, 528, 281, 1333, 295, 2642, 484, 322, 341, 4137, 13, 1485, 307, 11, 731, 11, 8679, 1025, 307, 4748, 1101, 813, 264, 6211, 510, 13, 286, 914, 11, 286, 500, 380, 519, 309, 311, 1101, 294, 604, 10995, 636, 11, 281, 312, 3245, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23891737150109332, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.7575967311859131}, {"id": 133, "seek": 162700, "start": 1643.0, "end": 1653.0, "text": " But it addresses this psychological problem that you want to feel like using the best method that you shouldn't discount the other ways of doing it because they might be worse.", "tokens": [51164, 583, 309, 16862, 341, 14346, 1154, 300, 291, 528, 281, 841, 411, 1228, 264, 1151, 3170, 300, 291, 4659, 380, 11635, 264, 661, 2098, 295, 884, 309, 570, 436, 1062, 312, 5324, 13, 51664], "temperature": 0.0, "avg_logprob": -0.23891737150109332, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.7575967311859131}, {"id": 134, "seek": 165300, "start": 1654.0, "end": 1672.0, "text": " And the other thing is that it doesn't make any practical difference whether you use the defaults or whether you perturb the HMM parameters and the guide trees. So, any one of these ways of building an alignment is equally good as far as we know.", "tokens": [50414, 400, 264, 661, 551, 307, 300, 309, 1177, 380, 652, 604, 8496, 2649, 1968, 291, 764, 264, 7576, 82, 420, 1968, 291, 40468, 264, 389, 17365, 9834, 293, 264, 5934, 5852, 13, 407, 11, 604, 472, 295, 613, 2098, 295, 2390, 364, 18515, 307, 12309, 665, 382, 1400, 382, 321, 458, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2209585734776088, "compression_ratio": 1.4385964912280702, "no_speech_prob": 0.4147389829158783}, {"id": 135, "seek": 167200, "start": 1673.0, "end": 1684.0, "text": " It performs equally well on the benchmark. Of course, some of them do better and worse on particular sets. But when you're starting with new data, you have no particular reason to prefer any of these variants.", "tokens": [50414, 467, 26213, 12309, 731, 322, 264, 18927, 13, 2720, 1164, 11, 512, 295, 552, 360, 1101, 293, 5324, 322, 1729, 6352, 13, 583, 562, 291, 434, 2891, 365, 777, 1412, 11, 291, 362, 572, 1729, 1778, 281, 4382, 604, 295, 613, 21669, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20122530105266165, "compression_ratio": 1.412162162162162, "no_speech_prob": 0.4184921681880951}, {"id": 136, "seek": 168400, "start": 1684.0, "end": 1701.0, "text": " And this means that you can generate your ensemble of alignments and they're equally trustworthy. So, now you can say, well, if they give different results, I have a problem. Or if they're giving consistent results, then, you know, I have good reason to feel more confident in them.", "tokens": [50364, 400, 341, 1355, 300, 291, 393, 8460, 428, 19492, 295, 7975, 1117, 293, 436, 434, 12309, 39714, 13, 407, 11, 586, 291, 393, 584, 11, 731, 11, 498, 436, 976, 819, 3542, 11, 286, 362, 257, 1154, 13, 1610, 498, 436, 434, 2902, 8398, 3542, 11, 550, 11, 291, 458, 11, 286, 362, 665, 1778, 281, 841, 544, 6679, 294, 552, 13, 51214], "temperature": 0.0, "avg_logprob": -0.20827765797459802, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.2566685974597931}, {"id": 137, "seek": 168400, "start": 1703.0, "end": 1708.0, "text": " I haven't really talked about nucleotide alignments, but it's a similar story.", "tokens": [51314, 286, 2378, 380, 534, 2825, 466, 14962, 310, 482, 7975, 1117, 11, 457, 309, 311, 257, 2531, 1657, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20827765797459802, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.2566685974597931}, {"id": 138, "seek": 171400, "start": 1715.0, "end": 1731.0, "text": " So, now I'm going back to sort of a concrete application of this whole approach. And so, I need to give a little background on RNA virus taxonomy.", "tokens": [50414, 407, 11, 586, 286, 478, 516, 646, 281, 1333, 295, 257, 9859, 3861, 295, 341, 1379, 3109, 13, 400, 370, 11, 286, 643, 281, 976, 257, 707, 3678, 322, 22484, 5752, 3366, 23423, 13, 51214], "temperature": 0.0, "avg_logprob": -0.19923681259155274, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.027579564601182938}, {"id": 139, "seek": 171400, "start": 1733.0, "end": 1737.0, "text": " And it's undergone some radical changes recently.", "tokens": [51314, 400, 309, 311, 833, 39743, 512, 12001, 2962, 3938, 13, 51514], "temperature": 0.0, "avg_logprob": -0.19923681259155274, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.027579564601182938}, {"id": 140, "seek": 173700, "start": 1738.0, "end": 1752.0, "text": " So, before 2018, so maybe I should quickly review taxonomy for people who have not heard of this. It's sort of a human classification state scheme. And it's sort of based on a tree-like", "tokens": [50414, 407, 11, 949, 6096, 11, 370, 1310, 286, 820, 2661, 3131, 3366, 23423, 337, 561, 567, 362, 406, 2198, 295, 341, 13, 467, 311, 1333, 295, 257, 1952, 21538, 1785, 12232, 13, 400, 309, 311, 1333, 295, 2361, 322, 257, 4230, 12, 4092, 51114], "temperature": 0.0, "avg_logprob": -0.28346731307658746, "compression_ratio": 1.2937062937062938, "no_speech_prob": 0.06007833406329155}, {"id": 141, "seek": 175200, "start": 1753.0, "end": 1776.0, "text": " sort of structure, which is supposed to follow phylogeny. And then it has ranks, which are species, genus, family, class, order, phylum, which are sort of human-level groups, but they're supposed to capture something meaningful about the organisms that you're classifying.", "tokens": [50414, 1333, 295, 3877, 11, 597, 307, 3442, 281, 1524, 903, 88, 4987, 43100, 13, 400, 550, 309, 575, 21406, 11, 597, 366, 6172, 11, 1049, 301, 11, 1605, 11, 1508, 11, 1668, 11, 903, 27512, 11, 597, 366, 1333, 295, 1952, 12, 12418, 3935, 11, 457, 436, 434, 3442, 281, 7983, 746, 10995, 466, 264, 22110, 300, 291, 434, 1508, 5489, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21739020492091324, "compression_ratio": 1.5542857142857143, "no_speech_prob": 0.5076978802680969}, {"id": 142, "seek": 177600, "start": 1777.0, "end": 1787.0, "text": " And they're supposed to follow the phylogenetic tree so that these groups are, you know, they're evolutionary relatives, not just things that you think look alike.", "tokens": [50414, 400, 436, 434, 3442, 281, 1524, 264, 903, 88, 4987, 268, 3532, 4230, 370, 300, 613, 3935, 366, 11, 291, 458, 11, 436, 434, 27567, 18201, 11, 406, 445, 721, 300, 291, 519, 574, 20025, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2233470735095796, "compression_ratio": 1.4054054054054055, "no_speech_prob": 0.09533638507127762}, {"id": 143, "seek": 177600, "start": 1788.0, "end": 1798.0, "text": " And before 2018, RNA viruses were not classified above order. There was no class or phylum rank.", "tokens": [50964, 400, 949, 6096, 11, 22484, 21785, 645, 406, 20627, 3673, 1668, 13, 821, 390, 572, 1508, 420, 903, 27512, 6181, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2233470735095796, "compression_ratio": 1.4054054054054055, "no_speech_prob": 0.09533638507127762}, {"id": 144, "seek": 179800, "start": 1799.0, "end": 1817.0, "text": " And the reason for that is that, well, how do you build trees for these viruses? Well, you use polymerase sequences, but these sequences evolve very quickly. And it becomes very, very difficult to make alignments and trees for the most distantly related groups.", "tokens": [50414, 400, 264, 1778, 337, 300, 307, 300, 11, 731, 11, 577, 360, 291, 1322, 5852, 337, 613, 21785, 30, 1042, 11, 291, 764, 20073, 651, 22978, 11, 457, 613, 22978, 16693, 588, 2661, 13, 400, 309, 3643, 588, 11, 588, 2252, 281, 652, 7975, 1117, 293, 5852, 337, 264, 881, 1483, 3627, 4077, 3935, 13, 51314], "temperature": 0.0, "avg_logprob": -0.22407169665320445, "compression_ratio": 1.535294117647059, "no_speech_prob": 0.13654771447181702}, {"id": 145, "seek": 181700, "start": 1818.0, "end": 1840.0, "text": " And then in 2018, a paper came along, which was highly influential, and it's Wolf 2018. And they went to a lot of effort to build a sort of global multiple alignment of all RNA viruses from their polymerases and build a tree from it.", "tokens": [50414, 400, 550, 294, 6096, 11, 257, 3035, 1361, 2051, 11, 597, 390, 5405, 22215, 11, 293, 309, 311, 16634, 6096, 13, 400, 436, 1437, 281, 257, 688, 295, 4630, 281, 1322, 257, 1333, 295, 4338, 3866, 18515, 295, 439, 22484, 21785, 490, 641, 20073, 1957, 293, 1322, 257, 4230, 490, 309, 13, 51514], "temperature": 0.0, "avg_logprob": -0.24085535321916854, "compression_ratio": 1.4036144578313252, "no_speech_prob": 0.5543555021286011}, {"id": 146, "seek": 184000, "start": 1841.0, "end": 1859.0, "text": " And this is sort of a figure from the paper, and I'm sort of capturing, I'm calling out here the bootstrap values on the deepest branches of this tree, which look very high.", "tokens": [50414, 400, 341, 307, 1333, 295, 257, 2573, 490, 264, 3035, 11, 293, 286, 478, 1333, 295, 23384, 11, 286, 478, 5141, 484, 510, 264, 11450, 372, 4007, 4190, 322, 264, 28288, 14770, 295, 341, 4230, 11, 597, 574, 588, 1090, 13, 51314], "temperature": 0.0, "avg_logprob": -0.22828598022460939, "compression_ratio": 1.3307692307692307, "no_speech_prob": 0.4920642077922821}, {"id": 147, "seek": 185900, "start": 1860.0, "end": 1878.0, "text": " And so that was very convincing to these guys and also to the sort of official virus taxonomists. And what they did was, you can see we've got those five colored branches. Those were adopted as phylum rank.", "tokens": [50414, 400, 370, 300, 390, 588, 24823, 281, 613, 1074, 293, 611, 281, 264, 1333, 295, 4783, 5752, 3366, 12481, 1751, 13, 400, 437, 436, 630, 390, 11, 291, 393, 536, 321, 600, 658, 729, 1732, 14332, 14770, 13, 3950, 645, 12175, 382, 903, 27512, 6181, 13, 51314], "temperature": 0.0, "avg_logprob": -0.26486406326293943, "compression_ratio": 1.3733333333333333, "no_speech_prob": 0.5810821056365967}, {"id": 148, "seek": 187800, "start": 1879.0, "end": 1893.0, "text": " So on the basis of this paper, RNA virus taxonomy was expanded to include phylum and class ranks. And when I saw this paper, it bothered me for about a year.", "tokens": [50414, 407, 322, 264, 5143, 295, 341, 3035, 11, 22484, 5752, 3366, 23423, 390, 14342, 281, 4090, 903, 27512, 293, 1508, 21406, 13, 400, 562, 286, 1866, 341, 3035, 11, 309, 22996, 385, 337, 466, 257, 1064, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2192428402784394, "compression_ratio": 1.2764227642276422, "no_speech_prob": 0.6583086252212524}, {"id": 149, "seek": 189300, "start": 1893.0, "end": 1907.0, "text": " So this is sort of the kind of the history behind how muscle five came about. Because I've played quite a bit with these polymerases, and I know how diverged they are.", "tokens": [50364, 407, 341, 307, 1333, 295, 264, 733, 295, 264, 2503, 2261, 577, 8679, 1732, 1361, 466, 13, 1436, 286, 600, 3737, 1596, 257, 857, 365, 613, 20073, 1957, 11, 293, 286, 458, 577, 18558, 3004, 436, 366, 13, 51064], "temperature": 0.0, "avg_logprob": -0.25719068190630745, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.6580867171287537}, {"id": 150, "seek": 189300, "start": 1907.0, "end": 1919.0, "text": " And I just looked at that and I said, I do not believe that tree. I just don't know, you just cannot align these things well enough to get this kind of reliability in a tree.", "tokens": [51064, 400, 286, 445, 2956, 412, 300, 293, 286, 848, 11, 286, 360, 406, 1697, 300, 4230, 13, 286, 445, 500, 380, 458, 11, 291, 445, 2644, 7975, 613, 721, 731, 1547, 281, 483, 341, 733, 295, 24550, 294, 257, 4230, 13, 51664], "temperature": 0.0, "avg_logprob": -0.25719068190630745, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.6580867171287537}, {"id": 151, "seek": 191900, "start": 1920.0, "end": 1935.0, "text": " How do you prove this is wrong? So, of course, now you've heard the rest of the talk, you have an idea about how I went to do that. But really, I just went around muttering, I don't believe it, this can't be right.", "tokens": [50414, 1012, 360, 291, 7081, 341, 307, 2085, 30, 407, 11, 295, 1164, 11, 586, 291, 600, 2198, 264, 1472, 295, 264, 751, 11, 291, 362, 364, 1558, 466, 577, 286, 1437, 281, 360, 300, 13, 583, 534, 11, 286, 445, 1437, 926, 5839, 34200, 11, 286, 500, 380, 1697, 309, 11, 341, 393, 380, 312, 558, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21914683940798738, "compression_ratio": 1.4951923076923077, "no_speech_prob": 0.20941774547100067}, {"id": 152, "seek": 191900, "start": 1935.0, "end": 1942.0, "text": " And this was sort of what I ultimately came up with as a response to my skepticism, if you like.", "tokens": [51164, 400, 341, 390, 1333, 295, 437, 286, 6284, 1361, 493, 365, 382, 257, 4134, 281, 452, 19128, 26356, 11, 498, 291, 411, 13, 51514], "temperature": 0.0, "avg_logprob": -0.21914683940798738, "compression_ratio": 1.4951923076923077, "no_speech_prob": 0.20941774547100067}, {"id": 153, "seek": 194200, "start": 1942.0, "end": 1958.0, "text": " So, yeah, so just to emphasize how difficult it is, the average distance between highly diverged viruses is five substitutions per site.", "tokens": [50364, 407, 11, 1338, 11, 370, 445, 281, 16078, 577, 2252, 309, 307, 11, 264, 4274, 4560, 1296, 5405, 18558, 3004, 21785, 307, 1732, 26441, 3666, 680, 3621, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2679998576641083, "compression_ratio": 1.2477064220183487, "no_speech_prob": 0.35573139786720276}, {"id": 154, "seek": 195800, "start": 1959.0, "end": 1981.0, "text": " So if you know anything about sort of protein alignment, protein evolution, so once you get something like 50% amino acid identity, which is 0.5 substitutions per site, it's already starting to get a little bit tricky.", "tokens": [50414, 407, 498, 291, 458, 1340, 466, 1333, 295, 7944, 18515, 11, 7944, 9303, 11, 370, 1564, 291, 483, 746, 411, 2625, 4, 24674, 8258, 6575, 11, 597, 307, 1958, 13, 20, 26441, 3666, 680, 3621, 11, 309, 311, 1217, 2891, 281, 483, 257, 707, 857, 12414, 13, 51514], "temperature": 0.0, "avg_logprob": -0.21775995516309551, "compression_ratio": 1.4064516129032258, "no_speech_prob": 0.7547451853752136}, {"id": 155, "seek": 198100, "start": 1981.0, "end": 1997.0, "text": " You've got some good regions, you've got some bad regions. Then if I get down anywhere close to one substitution per site, on average, I've got a different letter at every position and I'm well down into what's called the twilight zone.", "tokens": [50364, 509, 600, 658, 512, 665, 10682, 11, 291, 600, 658, 512, 1578, 10682, 13, 1396, 498, 286, 483, 760, 4992, 1998, 281, 472, 35827, 680, 3621, 11, 322, 4274, 11, 286, 600, 658, 257, 819, 5063, 412, 633, 2535, 293, 286, 478, 731, 760, 666, 437, 311, 1219, 264, 683, 27797, 6668, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2110223977462105, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.5581172704696655}, {"id": 156, "seek": 198100, "start": 1997.0, "end": 2009.0, "text": " And we're starting to get alignments that look like the WTF, the things that I was showing earlier. But we have gone five times deeper than that.", "tokens": [51164, 400, 321, 434, 2891, 281, 483, 7975, 1117, 300, 574, 411, 264, 343, 20527, 11, 264, 721, 300, 286, 390, 4099, 3071, 13, 583, 321, 362, 2780, 1732, 1413, 7731, 813, 300, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2110223977462105, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.5581172704696655}, {"id": 157, "seek": 200900, "start": 2009.0, "end": 2018.0, "text": " And so the conventional ability, excuse me, the conventional wisdom before 2018 was, well, the information's just lost.", "tokens": [50364, 400, 370, 264, 16011, 3485, 11, 8960, 385, 11, 264, 16011, 10712, 949, 6096, 390, 11, 731, 11, 264, 1589, 311, 445, 2731, 13, 50814], "temperature": 0.0, "avg_logprob": -0.3230207306998117, "compression_ratio": 1.2395833333333333, "no_speech_prob": 0.027576008811593056}, {"id": 158, "seek": 201800, "start": 2019.0, "end": 2032.0, "text": " So one of the things I did sort of in my skepticism was to really dig deep into that alignment. And I'm not going to go into the technical details here at all.", "tokens": [50414, 407, 472, 295, 264, 721, 286, 630, 1333, 295, 294, 452, 19128, 26356, 390, 281, 534, 2528, 2452, 666, 300, 18515, 13, 400, 286, 478, 406, 516, 281, 352, 666, 264, 6191, 4365, 510, 412, 439, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1950129532232517, "compression_ratio": 1.3032786885245902, "no_speech_prob": 0.3699623942375183}, {"id": 159, "seek": 203200, "start": 2032.0, "end": 2051.0, "text": " I'm just going to sort of say that while there are a few very well conserved catalytic residues in RNA virus polymerase, and I was able to show that many of those catalytic residues are not correctly aligned within this alignment.", "tokens": [50364, 286, 478, 445, 516, 281, 1333, 295, 584, 300, 1339, 456, 366, 257, 1326, 588, 731, 1014, 6913, 13192, 43658, 13141, 1247, 294, 22484, 5752, 20073, 651, 11, 293, 286, 390, 1075, 281, 855, 300, 867, 295, 729, 13192, 43658, 13141, 1247, 366, 406, 8944, 17962, 1951, 341, 18515, 13, 51314], "temperature": 0.0, "avg_logprob": -0.18599199365686486, "compression_ratio": 1.4556962025316456, "no_speech_prob": 0.6441018581390381}, {"id": 160, "seek": 205100, "start": 2051.0, "end": 2067.0, "text": " So this means that of something like 400 columns, none of them are aligned correctly. Because if you don't get the catalytic residues right, where you have the best conservation, you certainly haven't got the rest of it right.", "tokens": [50364, 407, 341, 1355, 300, 295, 746, 411, 8423, 13766, 11, 6022, 295, 552, 366, 17962, 8944, 13, 1436, 498, 291, 500, 380, 483, 264, 13192, 43658, 13141, 1247, 558, 11, 689, 291, 362, 264, 1151, 16185, 11, 291, 3297, 2378, 380, 658, 264, 1472, 295, 309, 558, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20271207245302872, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.20176781713962555}, {"id": 161, "seek": 205100, "start": 2067.0, "end": 2073.0, "text": " So this sort of bolstered my opinion that something was going wrong in it.", "tokens": [51164, 407, 341, 1333, 295, 8986, 3120, 292, 452, 4800, 300, 746, 390, 516, 2085, 294, 309, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20271207245302872, "compression_ratio": 1.5435897435897437, "no_speech_prob": 0.20176781713962555}, {"id": 162, "seek": 207300, "start": 2073.0, "end": 2089.0, "text": " So after having sort of refined, come up with muscle five and put it together, I could now apply it to the Wolf 2018 alignment and the tree.", "tokens": [50364, 407, 934, 1419, 1333, 295, 26201, 11, 808, 493, 365, 8679, 1732, 293, 829, 309, 1214, 11, 286, 727, 586, 3079, 309, 281, 264, 16634, 6096, 18515, 293, 264, 4230, 13, 51164], "temperature": 0.0, "avg_logprob": -0.30898824419294085, "compression_ratio": 1.1965811965811965, "no_speech_prob": 0.16661566495895386}, {"id": 163, "seek": 208900, "start": 2089.0, "end": 2106.0, "text": " So I needed to do two things. First of all, I had to show that my alignment was at least as good as theirs, because they went to all this effort to do the manual adjustment and whatever. And these guys have a very high reputation as the experts on RNA viruses.", "tokens": [50364, 407, 286, 2978, 281, 360, 732, 721, 13, 2386, 295, 439, 11, 286, 632, 281, 855, 300, 452, 18515, 390, 412, 1935, 382, 665, 382, 22760, 11, 570, 436, 1437, 281, 439, 341, 4630, 281, 360, 264, 9688, 17132, 293, 2035, 13, 400, 613, 1074, 362, 257, 588, 1090, 13061, 382, 264, 8572, 322, 22484, 21785, 13, 51214], "temperature": 0.0, "avg_logprob": -0.20504623162941854, "compression_ratio": 1.452513966480447, "no_speech_prob": 0.3275531828403473}, {"id": 164, "seek": 210600, "start": 2106.0, "end": 2124.0, "text": " So I make absolutely no claim that my alignment is good in any sense, but I can show that I get the catalytic residues right more often than they do. So I think there's a reasonable case that mine is at least as good as theirs.", "tokens": [50364, 407, 286, 652, 3122, 572, 3932, 300, 452, 18515, 307, 665, 294, 604, 2020, 11, 457, 286, 393, 855, 300, 286, 483, 264, 13192, 43658, 13141, 1247, 558, 544, 2049, 813, 436, 360, 13, 407, 286, 519, 456, 311, 257, 10585, 1389, 300, 3892, 307, 412, 1935, 382, 665, 382, 22760, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16717888857867266, "compression_ratio": 1.5257731958762886, "no_speech_prob": 0.3173198401927948}, {"id": 165, "seek": 210600, "start": 2124.0, "end": 2131.0, "text": " But then when I generate replicates, these groups just get shuffled.", "tokens": [51264, 583, 550, 562, 286, 8460, 3248, 299, 1024, 11, 613, 3935, 445, 483, 402, 33974, 13, 51614], "temperature": 0.0, "avg_logprob": -0.16717888857867266, "compression_ratio": 1.5257731958762886, "no_speech_prob": 0.3173198401927948}, {"id": 166, "seek": 213100, "start": 2131.0, "end": 2148.0, "text": " So my claim is that when you do the analysis using the muscle five ensemble, you can see that the fiber are not reproduced.", "tokens": [50364, 407, 452, 3932, 307, 300, 562, 291, 360, 264, 5215, 1228, 264, 8679, 1732, 19492, 11, 291, 393, 536, 300, 264, 12874, 366, 406, 11408, 1232, 13, 51214], "temperature": 0.0, "avg_logprob": -0.20206306826683781, "compression_ratio": 1.2424242424242424, "no_speech_prob": 0.6439154148101807}, {"id": 167, "seek": 214800, "start": 2148.0, "end": 2162.0, "text": " And this means that the high bootstraps you get in the Wolf 2018 tree must be artifacts of systematic errors in their alignment. And of course, like everybody else, they use progressive alignment to put things together.", "tokens": [50364, 400, 341, 1355, 300, 264, 1090, 11450, 19639, 1878, 291, 483, 294, 264, 16634, 6096, 4230, 1633, 312, 24617, 295, 27249, 13603, 294, 641, 18515, 13, 400, 295, 1164, 11, 411, 2201, 1646, 11, 436, 764, 16131, 18515, 281, 829, 721, 1214, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20992724100748697, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.46473824977874756}, {"id": 168, "seek": 214800, "start": 2162.0, "end": 2172.0, "text": " So I think that groups really reflect the big blocks that they assembled in the final stages of putting together their alignment.", "tokens": [51064, 407, 286, 519, 300, 3935, 534, 5031, 264, 955, 8474, 300, 436, 24204, 294, 264, 2572, 10232, 295, 3372, 1214, 641, 18515, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20992724100748697, "compression_ratio": 1.608294930875576, "no_speech_prob": 0.46473824977874756}, {"id": 169, "seek": 217200, "start": 2172.0, "end": 2190.0, "text": " So when I do the confidences my way, they're very low. So my methodology says I shouldn't believe my tree, and I believe that it shouldn't be believed.", "tokens": [50364, 407, 562, 286, 360, 264, 1497, 41298, 452, 636, 11, 436, 434, 588, 2295, 13, 407, 452, 24850, 1619, 286, 4659, 380, 1697, 452, 4230, 11, 293, 286, 1697, 300, 309, 4659, 380, 312, 7847, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21389970779418946, "compression_ratio": 1.3727272727272728, "no_speech_prob": 0.6891456246376038}, {"id": 170, "seek": 219000, "start": 2190.0, "end": 2207.0, "text": " So this is, of course, my minority opinion, and I'm currently trying to convince people that currently RNA virus taxonomy is kind of driven off the rails, and it's not meaningful at all.", "tokens": [50364, 407, 341, 307, 11, 295, 1164, 11, 452, 16166, 4800, 11, 293, 286, 478, 4362, 1382, 281, 13447, 561, 300, 4362, 22484, 5752, 3366, 23423, 307, 733, 295, 9555, 766, 264, 27649, 11, 293, 309, 311, 406, 10995, 412, 439, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2147524939643012, "compression_ratio": 1.3285714285714285, "no_speech_prob": 0.6717772483825684}, {"id": 171, "seek": 220700, "start": 2207.0, "end": 2225.0, "text": " And I think that's actually positively harmful. To get into that would be sort of a whole nother talk, but I'm just trying to use this as a case study to show how this approach can be applied to something in practice.", "tokens": [50364, 400, 286, 519, 300, 311, 767, 25795, 19727, 13, 1407, 483, 666, 300, 576, 312, 1333, 295, 257, 1379, 406, 511, 751, 11, 457, 286, 478, 445, 1382, 281, 764, 341, 382, 257, 1389, 2979, 281, 855, 577, 341, 3109, 393, 312, 6456, 281, 746, 294, 3124, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18399372467627892, "compression_ratio": 1.3821656050955413, "no_speech_prob": 0.5307697057723999}, {"id": 172, "seek": 222500, "start": 2225.0, "end": 2237.0, "text": " And so we actually got through this quicker than I thought. That's the muscle five paper. And thank you very much for the invitation.", "tokens": [50364, 400, 370, 321, 767, 658, 807, 341, 16255, 813, 286, 1194, 13, 663, 311, 264, 8679, 1732, 3035, 13, 400, 1309, 291, 588, 709, 337, 264, 17890, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2789662551879883, "compression_ratio": 1.3211678832116789, "no_speech_prob": 0.4684707522392273}, {"id": 173, "seek": 222500, "start": 2237.0, "end": 2243.0, "text": " Thank you.", "tokens": [50964, 1044, 291, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2789662551879883, "compression_ratio": 1.3211678832116789, "no_speech_prob": 0.4684707522392273}, {"id": 174, "seek": 222500, "start": 2243.0, "end": 2249.0, "text": " Now I think we'll be the QA session.", "tokens": [51264, 823, 286, 519, 321, 603, 312, 264, 1249, 32, 5481, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2789662551879883, "compression_ratio": 1.3211678832116789, "no_speech_prob": 0.4684707522392273}, {"id": 175, "seek": 224900, "start": 2249.0, "end": 2261.0, "text": " I think it's really amazing that, for me, I just go to use whatever multiple sequence alignment, and then you give me a high bootstrap value, I believe it, and call it a day.", "tokens": [50364, 286, 519, 309, 311, 534, 2243, 300, 11, 337, 385, 11, 286, 445, 352, 281, 764, 2035, 3866, 8310, 18515, 11, 293, 550, 291, 976, 385, 257, 1090, 11450, 372, 4007, 2158, 11, 286, 1697, 309, 11, 293, 818, 309, 257, 786, 13, 50964], "temperature": 0.0, "avg_logprob": -0.27626519350661444, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.708808183670044}, {"id": 176, "seek": 224900, "start": 2261.0, "end": 2277.0, "text": " And I really appreciate that this talk lead us into the details and how to be skeptical. And I think Kelvin and Luther have a question in the chat. Do you want to unmute yourself or maybe turn on the camera to speak for yourself?", "tokens": [50964, 400, 286, 534, 4449, 300, 341, 751, 1477, 505, 666, 264, 4365, 293, 577, 281, 312, 28601, 13, 400, 286, 519, 36955, 293, 20693, 362, 257, 1168, 294, 264, 5081, 13, 1144, 291, 528, 281, 41445, 1803, 420, 1310, 1261, 322, 264, 2799, 281, 1710, 337, 1803, 30, 51764], "temperature": 0.0, "avg_logprob": -0.27626519350661444, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.708808183670044}, {"id": 177, "seek": 227700, "start": 2277.0, "end": 2288.0, "text": " I'm sorry, I didn't quite catch that, but I do see a great question on the chat. It's a great question because now I wish I had done a couple of slides on this.", "tokens": [50364, 286, 478, 2597, 11, 286, 994, 380, 1596, 3745, 300, 11, 457, 286, 360, 536, 257, 869, 1168, 322, 264, 5081, 13, 467, 311, 257, 869, 1168, 570, 586, 286, 3172, 286, 632, 1096, 257, 1916, 295, 9788, 322, 341, 13, 50914], "temperature": 0.0, "avg_logprob": -0.21945457025007767, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.7215131521224976}, {"id": 178, "seek": 227700, "start": 2288.0, "end": 2305.0, "text": " And actually, this is what we're doing in the Serratus project right now. So you remember I gave a very quick slide on this project we did during the pandemic to discover new RNA viruses.", "tokens": [50914, 400, 767, 11, 341, 307, 437, 321, 434, 884, 294, 264, 4210, 4481, 301, 1716, 558, 586, 13, 407, 291, 1604, 286, 2729, 257, 588, 1702, 4137, 322, 341, 1716, 321, 630, 1830, 264, 5388, 281, 4411, 777, 22484, 21785, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21945457025007767, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.7215131521224976}, {"id": 179, "seek": 230500, "start": 2305.0, "end": 2320.0, "text": " And now we have this incredible resource with AlphaFold where we can discover much more highly diverged viruses by doing this folding.", "tokens": [50364, 400, 586, 321, 362, 341, 4651, 7684, 365, 20588, 37, 2641, 689, 321, 393, 4411, 709, 544, 5405, 18558, 3004, 21785, 538, 884, 341, 25335, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2248004913330078, "compression_ratio": 1.2407407407407407, "no_speech_prob": 0.04022893309593201}, {"id": 180, "seek": 232000, "start": 2320.0, "end": 2344.0, "text": " So, AlphaFold is very good at enabling us to find very highly diverged homologs. What the structural alignment, and I talked very briefly about this, but when you have distantly related structures, you can eyeball them in higher model, and you can see, okay, very", "tokens": [50364, 407, 11, 20588, 37, 2641, 307, 588, 665, 412, 23148, 505, 281, 915, 588, 5405, 18558, 3004, 3655, 1132, 82, 13, 708, 264, 15067, 18515, 11, 293, 286, 2825, 588, 10515, 466, 341, 11, 457, 562, 291, 362, 1483, 3627, 4077, 9227, 11, 291, 393, 38868, 552, 294, 2946, 2316, 11, 293, 291, 393, 536, 11, 1392, 11, 588, 51564], "temperature": 0.0, "avg_logprob": -0.25645973568870906, "compression_ratio": 1.4858757062146892, "no_speech_prob": 0.5887589454650879}, {"id": 181, "seek": 234400, "start": 2344.0, "end": 2361.0, "text": " clearly, you have a squiggle here and a squiggle here and the squiggles and the squoggles line up between the different structures. But you can't say, okay, but this cysteine residue exactly matches that aspartate residue in the other structure.", "tokens": [50364, 4448, 11, 291, 362, 257, 2339, 19694, 510, 293, 257, 2339, 19694, 510, 293, 264, 2339, 19469, 293, 264, 2339, 36754, 904, 1622, 493, 1296, 264, 819, 9227, 13, 583, 291, 393, 380, 584, 11, 1392, 11, 457, 341, 3185, 2941, 533, 34799, 2293, 10676, 300, 382, 6971, 473, 34799, 294, 264, 661, 3877, 13, 51214], "temperature": 0.0, "avg_logprob": -0.24382035206940214, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.9313617944717407}, {"id": 182, "seek": 236100, "start": 2361.0, "end": 2379.0, "text": " It's not that precise. So you might have a helix here and a helix here. So you can say, yeah, these secondary structures are the same. But now the homology is at that level. You can say secondary structure, yeah. But once you get to the level of an individual residue, it's not clear.", "tokens": [50364, 467, 311, 406, 300, 13600, 13, 407, 291, 1062, 362, 257, 801, 970, 510, 293, 257, 801, 970, 510, 13, 407, 291, 393, 584, 11, 1338, 11, 613, 11396, 9227, 366, 264, 912, 13, 583, 586, 264, 3655, 1793, 307, 412, 300, 1496, 13, 509, 393, 584, 11396, 3877, 11, 1338, 13, 583, 1564, 291, 483, 281, 264, 1496, 295, 364, 2609, 34799, 11, 309, 311, 406, 1850, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20011779053570472, "compression_ratio": 1.6511627906976745, "no_speech_prob": 0.7147506475448608}, {"id": 183, "seek": 237900, "start": 2379.0, "end": 2403.0, "text": " And it's probably not meaningful because there's been enough insertion and deletion that it's not really clear that there's a one-to-one evolutionary correspondence between the residues. What's being conserved here is the secondary structures. So what does that mean? It means you can recognize the polymerases and you can do that with a very high degree of confidence from the structures.", "tokens": [50364, 400, 309, 311, 1391, 406, 10995, 570, 456, 311, 668, 1547, 8969, 313, 293, 1103, 302, 313, 300, 309, 311, 406, 534, 1850, 300, 456, 311, 257, 472, 12, 1353, 12, 546, 27567, 38135, 1296, 264, 13141, 1247, 13, 708, 311, 885, 1014, 6913, 510, 307, 264, 11396, 9227, 13, 407, 437, 775, 300, 914, 30, 467, 1355, 291, 393, 5521, 264, 20073, 1957, 293, 291, 393, 360, 300, 365, 257, 588, 1090, 4314, 295, 6687, 490, 264, 9227, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21259341921125138, "compression_ratio": 1.6623931623931625, "no_speech_prob": 0.519288957118988}, {"id": 184, "seek": 240300, "start": 2403.0, "end": 2428.0, "text": " But what you can't do is build trees because you can't get evolutionary distances between structures. You can only get evolutionary distances from sequences. And even that's questionable. So what do you actually do to build those kinds of trees? You do maximum likelihood. And what's maximum likelihood?", "tokens": [50364, 583, 437, 291, 393, 380, 360, 307, 1322, 5852, 570, 291, 393, 380, 483, 27567, 22182, 1296, 9227, 13, 509, 393, 787, 483, 27567, 22182, 490, 22978, 13, 400, 754, 300, 311, 37158, 13, 407, 437, 360, 291, 767, 360, 281, 1322, 729, 3685, 295, 5852, 30, 509, 360, 6674, 22119, 13, 400, 437, 311, 6674, 22119, 30, 51614], "temperature": 0.0, "avg_logprob": -0.2011592157425419, "compression_ratio": 1.7118644067796611, "no_speech_prob": 0.8822404742240906}, {"id": 185, "seek": 242800, "start": 2428.0, "end": 2450.0, "text": " This is Moses coming down with some tablets that have a very, very simplified model of evolution written on them, saying, OK, well, there's this transition probability, that transversion probability. And there's all kinds of fancy math. But what that math boils down to is an incredibly oversimplified model of evolution.", "tokens": [50364, 639, 307, 17580, 1348, 760, 365, 512, 27622, 300, 362, 257, 588, 11, 588, 26335, 2316, 295, 9303, 3720, 322, 552, 11, 1566, 11, 2264, 11, 731, 11, 456, 311, 341, 6034, 8482, 11, 300, 1145, 29153, 8482, 13, 400, 456, 311, 439, 3685, 295, 10247, 5221, 13, 583, 437, 300, 5221, 35049, 760, 281, 307, 364, 6252, 15488, 332, 564, 2587, 2316, 295, 9303, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21471732003348215, "compression_ratio": 1.6294416243654823, "no_speech_prob": 0.9135521650314331}, {"id": 186, "seek": 245000, "start": 2450.0, "end": 2476.0, "text": " And, well, that's the best we can do. And it surely works very well in reasonable cases. But here we're at five or six substitutions per site. So we are pushing sort of a model which no doubt works very well over short distances to extremely large distances. And that surely just doesn't work. And with structures we don't have an evolutionary distance.", "tokens": [50364, 400, 11, 731, 11, 300, 311, 264, 1151, 321, 393, 360, 13, 400, 309, 11468, 1985, 588, 731, 294, 10585, 3331, 13, 583, 510, 321, 434, 412, 1732, 420, 2309, 26441, 3666, 680, 3621, 13, 407, 321, 366, 7380, 1333, 295, 257, 2316, 597, 572, 6385, 1985, 588, 731, 670, 2099, 22182, 281, 4664, 2416, 22182, 13, 400, 300, 11468, 445, 1177, 380, 589, 13, 400, 365, 9227, 321, 500, 380, 362, 364, 27567, 4560, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2018648386001587, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.9121435880661011}, {"id": 187, "seek": 247600, "start": 2476.0, "end": 2505.0, "text": " So you can say, well, this maybe looks more similar to that. But it doesn't tell you whether it's an evolutionary neighbor or not. So there's this classic issue which people can sometimes forget. So let's say you have a blast top hit. Is it to a polymerase, a virus polymerase, or to a group two intron, or a CRISPR-Cas protein? These are all in the same superfamily. They're all pandamine proteins.", "tokens": [50414, 407, 291, 393, 584, 11, 731, 11, 341, 1310, 1542, 544, 2531, 281, 300, 13, 583, 309, 1177, 380, 980, 291, 1968, 309, 311, 364, 27567, 5987, 420, 406, 13, 407, 456, 311, 341, 7230, 2734, 597, 561, 393, 2171, 2870, 13, 407, 718, 311, 584, 291, 362, 257, 12035, 1192, 2045, 13, 1119, 309, 281, 257, 20073, 651, 11, 257, 5752, 20073, 651, 11, 420, 281, 257, 1594, 732, 560, 2044, 11, 420, 257, 49256, 15958, 12, 34, 296, 7944, 30, 1981, 366, 439, 294, 264, 912, 1687, 44433, 13, 814, 434, 439, 4565, 18929, 15577, 13, 51814], "temperature": 0.0, "avg_logprob": -0.21530986068272354, "compression_ratio": 1.55859375, "no_speech_prob": 0.7428427338600159}, {"id": 188, "seek": 250600, "start": 2506.0, "end": 2530.0, "text": " And you can look at the top hit and say, OK, the top hit is a virus. It's probably a virus, which is true. But it's not necessarily a virus. It could be a highly diverged group two intron. It's just that the way blast ranks them is not the way it doesn't necessarily reflect what's the closest in the tree. When you're looking at structures, you have the same problem. You can say, well, this structure looks more like that structure.", "tokens": [50364, 400, 291, 393, 574, 412, 264, 1192, 2045, 293, 584, 11, 2264, 11, 264, 1192, 2045, 307, 257, 5752, 13, 467, 311, 1391, 257, 5752, 11, 597, 307, 2074, 13, 583, 309, 311, 406, 4725, 257, 5752, 13, 467, 727, 312, 257, 5405, 18558, 3004, 1594, 732, 560, 2044, 13, 467, 311, 445, 300, 264, 636, 12035, 21406, 552, 307, 406, 264, 636, 309, 1177, 380, 4725, 5031, 437, 311, 264, 13699, 294, 264, 4230, 13, 1133, 291, 434, 1237, 412, 9227, 11, 291, 362, 264, 912, 1154, 13, 509, 393, 584, 11, 731, 11, 341, 3877, 1542, 544, 411, 300, 3877, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16582448014589113, "compression_ratio": 1.736, "no_speech_prob": 0.42216184735298157}, {"id": 189, "seek": 253000, "start": 2530.0, "end": 2552.0, "text": " And you can say, OK, it has a DALI z-score or a TMI score or whatever, which is closer. But that doesn't necessarily mean it's the closest evolutionary relative. So alpha fold is adding a lot of capability here. But it doesn't resolve the deep evolutionary history of these viruses.", "tokens": [50364, 400, 291, 393, 584, 11, 2264, 11, 309, 575, 257, 413, 11566, 710, 12, 4417, 418, 420, 257, 314, 13808, 6175, 420, 2035, 11, 597, 307, 4966, 13, 583, 300, 1177, 380, 4725, 914, 309, 311, 264, 13699, 27567, 4972, 13, 407, 8961, 4860, 307, 5127, 257, 688, 295, 13759, 510, 13, 583, 309, 1177, 380, 14151, 264, 2452, 27567, 2503, 295, 613, 21785, 13, 51464], "temperature": 0.0, "avg_logprob": -0.258358730989344, "compression_ratio": 1.4764397905759161, "no_speech_prob": 0.4376831650733948}, {"id": 190, "seek": 256000, "start": 2560.0, "end": 2576.0, "text": " So the question is, does muscle work equally well for nucleotides as for amino acid sequences? So the question here is, well, what's your standard of accuracy? And so I don't think you can directly compare them.", "tokens": [50364, 407, 264, 1168, 307, 11, 775, 8679, 589, 12309, 731, 337, 14962, 310, 1875, 382, 337, 24674, 8258, 22978, 30, 407, 264, 1168, 510, 307, 11, 731, 11, 437, 311, 428, 3832, 295, 14170, 30, 400, 370, 286, 500, 380, 519, 291, 393, 3838, 6794, 552, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17108528286803001, "compression_ratio": 1.4066666666666667, "no_speech_prob": 0.9097242951393127}, {"id": 191, "seek": 257600, "start": 2576.0, "end": 2593.0, "text": " If you saw on BarbieBase, the best methods only get 50% to 60% of columns correct. But they're incredibly challenging alignments, where probably most of the columns are not even meaningful anyway.", "tokens": [50364, 759, 291, 1866, 322, 14876, 414, 33, 651, 11, 264, 1151, 7150, 787, 483, 2625, 4, 281, 4060, 4, 295, 13766, 3006, 13, 583, 436, 434, 6252, 7595, 7975, 1117, 11, 689, 1391, 881, 295, 264, 13766, 366, 406, 754, 10995, 4033, 13, 51214], "temperature": 0.0, "avg_logprob": -0.31190537391824924, "compression_ratio": 1.3066666666666666, "no_speech_prob": 0.6788650155067444}, {"id": 192, "seek": 259300, "start": 2593.0, "end": 2622.0, "text": " So it really depends. What's your benchmark? What's your standard of accuracy? I mean, it works well. And it also is slightly better than the competition. When you do a benchmark, does that matter in practice? I would say no. I would say the important thing is that you have this ability to muscle will, by generating the ensemble, muscle will tell you whether it's good enough for your problem or not.", "tokens": [50364, 407, 309, 534, 5946, 13, 708, 311, 428, 18927, 30, 708, 311, 428, 3832, 295, 14170, 30, 286, 914, 11, 309, 1985, 731, 13, 400, 309, 611, 307, 4748, 1101, 813, 264, 6211, 13, 1133, 291, 360, 257, 18927, 11, 775, 300, 1871, 294, 3124, 30, 286, 576, 584, 572, 13, 286, 576, 584, 264, 1021, 551, 307, 300, 291, 362, 341, 3485, 281, 8679, 486, 11, 538, 17746, 264, 19492, 11, 8679, 486, 980, 291, 1968, 309, 311, 665, 1547, 337, 428, 1154, 420, 406, 13, 51814], "temperature": 0.0, "avg_logprob": -0.2051551525409405, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.695631206035614}, {"id": 193, "seek": 262200, "start": 2622.0, "end": 2640.0, "text": " And this is a gaping hole in bioinformatics tool in general, is you might have a confidence or a probability, but you're trusting all the assumptions in the algorithm are good enough that it can be trusted to come up with its own confidence.", "tokens": [50364, 400, 341, 307, 257, 7417, 278, 5458, 294, 12198, 37811, 30292, 2290, 294, 2674, 11, 307, 291, 1062, 362, 257, 6687, 420, 257, 8482, 11, 457, 291, 434, 28235, 439, 264, 17695, 294, 264, 9284, 366, 665, 1547, 300, 309, 393, 312, 16034, 281, 808, 493, 365, 1080, 1065, 6687, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20358361330899324, "compression_ratio": 1.4695121951219512, "no_speech_prob": 0.6616432666778564}, {"id": 194, "seek": 264000, "start": 2640.0, "end": 2667.0, "text": " And sometimes that's not the case, because like when you saw with bootstrap values, sometimes you get high bootstraps for wrong trees. So here muscle is helping you answer the question, is the method good enough to answer the biological question I'm trying to answer?", "tokens": [50364, 400, 2171, 300, 311, 406, 264, 1389, 11, 570, 411, 562, 291, 1866, 365, 11450, 372, 4007, 4190, 11, 2171, 291, 483, 1090, 11450, 19639, 1878, 337, 2085, 5852, 13, 407, 510, 8679, 307, 4315, 291, 1867, 264, 1168, 11, 307, 264, 3170, 665, 1547, 281, 1867, 264, 13910, 1168, 286, 478, 1382, 281, 1867, 30, 51714], "temperature": 0.0, "avg_logprob": -0.1940245787302653, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.6073768734931946}, {"id": 195, "seek": 266700, "start": 2667.0, "end": 2687.0, "text": " Could I comment on methods that estimate phylogeny and alignment simultaneously? So that would require a very long answer to go in detail. But I would say generally, so conceptually, it's the right thing to do.", "tokens": [50364, 7497, 286, 2871, 322, 7150, 300, 12539, 903, 88, 4987, 43100, 293, 18515, 16561, 30, 407, 300, 576, 3651, 257, 588, 938, 1867, 281, 352, 294, 2607, 13, 583, 286, 576, 584, 5101, 11, 370, 3410, 671, 11, 309, 311, 264, 558, 551, 281, 360, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1927364158630371, "compression_ratio": 1.390728476821192, "no_speech_prob": 0.6615861654281616}, {"id": 196, "seek": 268700, "start": 2687.0, "end": 2702.0, "text": " In practice, it's so computationally expensive, these methods, they're too slow to be usable in practice. And the accuracy is quite bad, because they just can't, it's just too hard to implement.", "tokens": [50364, 682, 3124, 11, 309, 311, 370, 24903, 379, 5124, 11, 613, 7150, 11, 436, 434, 886, 2964, 281, 312, 29975, 294, 3124, 13, 400, 264, 14170, 307, 1596, 1578, 11, 570, 436, 445, 393, 380, 11, 309, 311, 445, 886, 1152, 281, 4445, 13, 51114], "temperature": 0.0, "avg_logprob": -0.22899381319681802, "compression_ratio": 1.3857142857142857, "no_speech_prob": 0.8394851088523865}, {"id": 197, "seek": 270200, "start": 2702.0, "end": 2718.0, "text": " And when you do it, when you do that kind of thing, you're still using these grotesquely oversimplified models. So I want you to keep in mind, MOSE is coming down with these laws, and proteins don't respect these laws whatsoever.", "tokens": [50364, 400, 562, 291, 360, 309, 11, 562, 291, 360, 300, 733, 295, 551, 11, 291, 434, 920, 1228, 613, 677, 17251, 358, 736, 15488, 332, 564, 2587, 5245, 13, 407, 286, 528, 291, 281, 1066, 294, 1575, 11, 376, 40097, 307, 1348, 760, 365, 613, 6064, 11, 293, 15577, 500, 380, 3104, 613, 6064, 17076, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20546162923177083, "compression_ratio": 1.4223602484472049, "no_speech_prob": 0.6924110054969788}, {"id": 198, "seek": 271800, "start": 2718.0, "end": 2735.0, "text": " Proteins live in a very, very complicated world with selection pressure and biochemistry and everything going on. They don't think about blossom scores. So if you're a method that's trying to estimate phylogeny and alignment at the same time, it's starting from the wrong place.", "tokens": [50364, 43371, 1292, 1621, 294, 257, 588, 11, 588, 6179, 1002, 365, 9450, 3321, 293, 12198, 48353, 293, 1203, 516, 322, 13, 814, 500, 380, 519, 466, 38524, 13444, 13, 407, 498, 291, 434, 257, 3170, 300, 311, 1382, 281, 12539, 903, 88, 4987, 43100, 293, 18515, 412, 264, 912, 565, 11, 309, 311, 2891, 490, 264, 2085, 1081, 13, 51214], "temperature": 0.0, "avg_logprob": -0.18395090860033791, "compression_ratio": 1.4866310160427807, "no_speech_prob": 0.9271097779273987}, {"id": 199, "seek": 273500, "start": 2735.0, "end": 2758.0, "text": " It's starting from this highly simplified model of evolution. And however much sort of added bells and whistles you put into that model, it's still extremely oversimplified. So you're kind of pushing in a direction which is, it's like the physicist with the spherical cow.", "tokens": [50364, 467, 311, 2891, 490, 341, 5405, 26335, 2316, 295, 9303, 13, 400, 4461, 709, 1333, 295, 3869, 25474, 293, 49282, 291, 829, 666, 300, 2316, 11, 309, 311, 920, 4664, 15488, 332, 564, 2587, 13, 407, 291, 434, 733, 295, 7380, 294, 257, 3513, 597, 307, 11, 309, 311, 411, 264, 42466, 365, 264, 37300, 8408, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1979152648175349, "compression_ratio": 1.4863387978142077, "no_speech_prob": 0.3591878116130829}, {"id": 200, "seek": 275800, "start": 2758.0, "end": 2771.0, "text": " Okay, so we're adding two spherical horns to the spherical cow, but we're still a long way from the cow.", "tokens": [50364, 1033, 11, 370, 321, 434, 5127, 732, 37300, 28818, 281, 264, 37300, 8408, 11, 457, 321, 434, 920, 257, 938, 636, 490, 264, 8408, 13, 51014], "temperature": 0.0, "avg_logprob": -0.24241704032534644, "compression_ratio": 1.25, "no_speech_prob": 0.5072783827781677}, {"id": 201, "seek": 275800, "start": 2771.0, "end": 2776.0, "text": " Awesome. And Zarif, please ask your question.", "tokens": [51014, 10391, 13, 400, 41580, 351, 11, 1767, 1029, 428, 1168, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24241704032534644, "compression_ratio": 1.25, "no_speech_prob": 0.5072783827781677}, {"id": 202, "seek": 277600, "start": 2776.0, "end": 2799.0, "text": " I was just wondering, and by no means, my research is on phylogeny and evolution, but I'm just wondering when you are doing these trees and alignments, so can you take information from some other closely related proteins when you are doing the phylogeny", "tokens": [50364, 286, 390, 445, 6359, 11, 293, 538, 572, 1355, 11, 452, 2132, 307, 322, 903, 88, 4987, 43100, 293, 9303, 11, 457, 286, 478, 445, 6359, 562, 291, 366, 884, 613, 5852, 293, 7975, 1117, 11, 370, 393, 291, 747, 1589, 490, 512, 661, 8185, 4077, 15577, 562, 291, 366, 884, 264, 903, 88, 4987, 43100, 51514], "temperature": 0.0, "avg_logprob": -0.23848849932352703, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.8803977966308594}, {"id": 203, "seek": 279900, "start": 2799.0, "end": 2810.0, "text": " and take information from trees constructed from other proteins to make your phylogeny or alignment better?", "tokens": [50364, 293, 747, 1589, 490, 5852, 17083, 490, 661, 15577, 281, 652, 428, 903, 88, 4987, 43100, 420, 18515, 1101, 30, 50914], "temperature": 0.0, "avg_logprob": -0.2838708559672038, "compression_ratio": 1.2298850574712643, "no_speech_prob": 0.8721649646759033}, {"id": 204, "seek": 281000, "start": 2811.0, "end": 2830.0, "text": " So the short answer is no. And there are two reasons for that. One is the polymerase is the only gene that you find in all RNA viruses. So even within a family like coronavirus, there's quite a lot of variation in the gene content.", "tokens": [50414, 407, 264, 2099, 1867, 307, 572, 13, 400, 456, 366, 732, 4112, 337, 300, 13, 1485, 307, 264, 20073, 651, 307, 264, 787, 12186, 300, 291, 915, 294, 439, 22484, 21785, 13, 407, 754, 1951, 257, 1605, 411, 13043, 11, 456, 311, 1596, 257, 688, 295, 12990, 294, 264, 12186, 2701, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2069462878363473, "compression_ratio": 1.4528301886792452, "no_speech_prob": 0.4524877369403839}, {"id": 205, "seek": 283000, "start": 2830.0, "end": 2844.0, "text": " If you go deep, there is nothing except the polymerase. So that's one problem. The other problem is that the other genes typically evolve much more quickly than the polymerase.", "tokens": [50364, 759, 291, 352, 2452, 11, 456, 307, 1825, 3993, 264, 20073, 651, 13, 407, 300, 311, 472, 1154, 13, 440, 661, 1154, 307, 300, 264, 661, 14424, 5850, 16693, 709, 544, 2661, 813, 264, 20073, 651, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21401489071729707, "compression_ratio": 1.4426229508196722, "no_speech_prob": 0.7980335354804993}, {"id": 206, "seek": 284400, "start": 2844.0, "end": 2866.0, "text": " So they're much harder to align, and it's just not adding anything useful. I mean, even between two different species, you get about 90% polymerase identity. So that's enough distance that you can clearly separate species.", "tokens": [50364, 407, 436, 434, 709, 6081, 281, 7975, 11, 293, 309, 311, 445, 406, 5127, 1340, 4420, 13, 286, 914, 11, 754, 1296, 732, 819, 6172, 11, 291, 483, 466, 4289, 4, 20073, 651, 6575, 13, 407, 300, 311, 1547, 4560, 300, 291, 393, 4448, 4994, 6172, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20977184819240197, "compression_ratio": 1.361963190184049, "no_speech_prob": 0.48804783821105957}, {"id": 207, "seek": 286600, "start": 2866.0, "end": 2881.0, "text": " The other genes really isn't adding anything helpful, and they're evolving much more quickly, so they're harder to align. So in any case I can think of, you're better off throwing the other genes away and just focusing on the polymerase.", "tokens": [50364, 440, 661, 14424, 534, 1943, 380, 5127, 1340, 4961, 11, 293, 436, 434, 21085, 709, 544, 2661, 11, 370, 436, 434, 6081, 281, 7975, 13, 407, 294, 604, 1389, 286, 393, 519, 295, 11, 291, 434, 1101, 766, 10238, 264, 661, 14424, 1314, 293, 445, 8416, 322, 264, 20073, 651, 13, 51114], "temperature": 0.0, "avg_logprob": -0.23539355884898794, "compression_ratio": 1.4720496894409938, "no_speech_prob": 0.952269434928894}, {"id": 208, "seek": 288100, "start": 2881.0, "end": 2903.0, "text": " It's only if you're looking at a very, very fine grained detail, like let's say Omicron variant of COVID versus some other variant, then you're looking at the other genes. But as soon as you go any deeper than that, you're better off focusing just on the polymerase.", "tokens": [50364, 467, 311, 787, 498, 291, 434, 1237, 412, 257, 588, 11, 588, 2489, 1295, 2001, 2607, 11, 411, 718, 311, 584, 9757, 299, 2044, 17501, 295, 4566, 5717, 512, 661, 17501, 11, 550, 291, 434, 1237, 412, 264, 661, 14424, 13, 583, 382, 2321, 382, 291, 352, 604, 7731, 813, 300, 11, 291, 434, 1101, 766, 8416, 445, 322, 264, 20073, 651, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20088073353708527, "compression_ratio": 1.5463414634146342, "no_speech_prob": 0.21990007162094116}, {"id": 209, "seek": 288100, "start": 2903.0, "end": 2908.0, "text": " Nice. Can you check Olivia's question in the chat?", "tokens": [51464, 5490, 13, 1664, 291, 1520, 26023, 311, 1168, 294, 264, 5081, 30, 51714], "temperature": 0.0, "avg_logprob": -0.20088073353708527, "compression_ratio": 1.5463414634146342, "no_speech_prob": 0.21990007162094116}, {"id": 210, "seek": 290800, "start": 2908.0, "end": 2916.0, "text": " What do I think the ideal method of RNA virus classification is?", "tokens": [50364, 708, 360, 286, 519, 264, 7157, 3170, 295, 22484, 5752, 21538, 307, 30, 50764], "temperature": 0.0, "avg_logprob": -0.28793734974331325, "compression_ratio": 1.2456140350877194, "no_speech_prob": 0.6786889433860779}, {"id": 211, "seek": 290800, "start": 2916.0, "end": 2923.0, "text": " So I just addressed the issue of whether it helps use the rest of the genome.", "tokens": [50764, 407, 286, 445, 13847, 264, 2734, 295, 1968, 309, 3665, 764, 264, 1472, 295, 264, 21953, 13, 51114], "temperature": 0.0, "avg_logprob": -0.28793734974331325, "compression_ratio": 1.2456140350877194, "no_speech_prob": 0.6786889433860779}, {"id": 212, "seek": 292300, "start": 2923.0, "end": 2944.0, "text": " And I think that, well, so yes. So here the issue is, when your traditional taxonomy, you culture a microbe and you grow it in some cells and you take photographs of it, you see what kinds of cells it infects.", "tokens": [50364, 400, 286, 519, 300, 11, 731, 11, 370, 2086, 13, 407, 510, 264, 2734, 307, 11, 562, 428, 5164, 3366, 23423, 11, 291, 3713, 257, 4532, 650, 293, 291, 1852, 309, 294, 512, 5438, 293, 291, 747, 17649, 295, 309, 11, 291, 536, 437, 3685, 295, 5438, 309, 5888, 82, 13, 51414], "temperature": 0.0, "avg_logprob": -0.29527698863636365, "compression_ratio": 1.4315068493150684, "no_speech_prob": 0.6751025319099426}, {"id": 213, "seek": 294400, "start": 2945.0, "end": 2961.0, "text": " So it's very labor intensive focus on a single virus. So a project like Serratus finds 100,000 viruses, we're not doing that kind of analysis. Basically we're giving you a polymerase sequence. So, and we don't know very much else about it, typically.", "tokens": [50414, 407, 309, 311, 588, 5938, 18957, 1879, 322, 257, 2167, 5752, 13, 407, 257, 1716, 411, 4210, 4481, 301, 10704, 2319, 11, 1360, 21785, 11, 321, 434, 406, 884, 300, 733, 295, 5215, 13, 8537, 321, 434, 2902, 291, 257, 20073, 651, 8310, 13, 407, 11, 293, 321, 500, 380, 458, 588, 709, 1646, 466, 309, 11, 5850, 13, 51214], "temperature": 0.0, "avg_logprob": -0.24645999121287512, "compression_ratio": 1.4124293785310735, "no_speech_prob": 0.8944875597953796}, {"id": 214, "seek": 296100, "start": 2961.0, "end": 2984.0, "text": " But kind of by definition, that's what we've got to work with and we want to classify those sequences. And this is generally a problem in all of microbial biology right now is that we're uncovering this vast world of viruses and bacteria, fungi, which are only known from metagenomic sequences.", "tokens": [50364, 583, 733, 295, 538, 7123, 11, 300, 311, 437, 321, 600, 658, 281, 589, 365, 293, 321, 528, 281, 33872, 729, 22978, 13, 400, 341, 307, 5101, 257, 1154, 294, 439, 295, 49713, 831, 14956, 558, 586, 307, 300, 321, 434, 21694, 278, 341, 8369, 1002, 295, 21785, 293, 11763, 11, 48772, 11, 597, 366, 787, 2570, 490, 1131, 4698, 21401, 22978, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2157757602520843, "compression_ratio": 1.5076923076923077, "no_speech_prob": 0.9108478426933289}, {"id": 215, "seek": 298400, "start": 2985.0, "end": 3006.0, "text": " And you can say, well, how do we do taxonomy with those and maybe just don't do taxonomy, maybe do computational classification and you call it something else. I think this was the mistake that the virus people made, to be honest, because with bacteria and fungi, we have that problem, but people don't try to make official taxonomy.", "tokens": [50414, 400, 291, 393, 584, 11, 731, 11, 577, 360, 321, 360, 3366, 23423, 365, 729, 293, 1310, 445, 500, 380, 360, 3366, 23423, 11, 1310, 360, 28270, 21538, 293, 291, 818, 309, 746, 1646, 13, 286, 519, 341, 390, 264, 6146, 300, 264, 5752, 561, 1027, 11, 281, 312, 3245, 11, 570, 365, 11763, 293, 48772, 11, 321, 362, 300, 1154, 11, 457, 561, 500, 380, 853, 281, 652, 4783, 3366, 23423, 13, 51464], "temperature": 0.0, "avg_logprob": -0.22765627774325284, "compression_ratio": 1.6323529411764706, "no_speech_prob": 0.833057165145874}, {"id": 216, "seek": 300600, "start": 3007.0, "end": 3032.0, "text": " But the virus guys elevated these debatable polymerase trees and made official taxonomy out of them. So I think they should have made a distinction between the sort of big picture computational things and what the fine grain study in the lab. And this is really confusing to people that are not intimately familiar with", "tokens": [50414, 583, 264, 5752, 1074, 23457, 613, 3001, 31415, 20073, 651, 5852, 293, 1027, 4783, 3366, 23423, 484, 295, 552, 13, 407, 286, 519, 436, 820, 362, 1027, 257, 16844, 1296, 264, 1333, 295, 955, 3036, 28270, 721, 293, 437, 264, 2489, 12837, 2979, 294, 264, 2715, 13, 400, 341, 307, 534, 13181, 281, 561, 300, 366, 406, 560, 5401, 4963, 365, 51664], "temperature": 0.0, "avg_logprob": -0.31402144798865683, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.865095853805542}, {"id": 217, "seek": 303200, "start": 3033.0, "end": 3035.0, "text": " how virus taxonomy is done.", "tokens": [50414, 577, 5752, 3366, 23423, 307, 1096, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2827665475698618, "compression_ratio": 1.3836477987421383, "no_speech_prob": 0.2068634182214737}, {"id": 218, "seek": 303200, "start": 3036.0, "end": 3043.0, "text": " So it's a scope to improve strategy for guide tree estimation and merging of subalignments.", "tokens": [50564, 407, 309, 311, 257, 11923, 281, 3470, 5206, 337, 5934, 4230, 35701, 293, 44559, 295, 1422, 304, 788, 1117, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2827665475698618, "compression_ratio": 1.3836477987421383, "no_speech_prob": 0.2068634182214737}, {"id": 219, "seek": 303200, "start": 3047.0, "end": 3049.0, "text": " I think this is so", "tokens": [51114, 286, 519, 341, 307, 370, 51214], "temperature": 0.0, "avg_logprob": -0.2827665475698618, "compression_ratio": 1.3836477987421383, "no_speech_prob": 0.2068634182214737}, {"id": 220, "seek": 303200, "start": 3051.0, "end": 3058.0, "text": " I'm sure there is. I mean, obviously, if I had ideas, I would have done them. But", "tokens": [51314, 286, 478, 988, 456, 307, 13, 286, 914, 11, 2745, 11, 498, 286, 632, 3487, 11, 286, 576, 362, 1096, 552, 13, 583, 51664], "temperature": 0.0, "avg_logprob": -0.2827665475698618, "compression_ratio": 1.3836477987421383, "no_speech_prob": 0.2068634182214737}, {"id": 221, "seek": 305800, "start": 3058.0, "end": 3066.0, "text": " I want to sort of seize on the sort of a conceptual issue in this question, which is always the search for the best method.", "tokens": [50364, 286, 528, 281, 1333, 295, 33413, 322, 264, 1333, 295, 257, 24106, 2734, 294, 341, 1168, 11, 597, 307, 1009, 264, 3164, 337, 264, 1151, 3170, 13, 50764], "temperature": 0.0, "avg_logprob": -0.22877404139592097, "compression_ratio": 1.5723270440251573, "no_speech_prob": 0.05180864781141281}, {"id": 222, "seek": 305800, "start": 3067.0, "end": 3074.0, "text": " And of course, this is a very good search. And I'm a very competitive guy. I want to have the best method when I make one. But", "tokens": [50814, 400, 295, 1164, 11, 341, 307, 257, 588, 665, 3164, 13, 400, 286, 478, 257, 588, 10043, 2146, 13, 286, 528, 281, 362, 264, 1151, 3170, 562, 286, 652, 472, 13, 583, 51164], "temperature": 0.0, "avg_logprob": -0.22877404139592097, "compression_ratio": 1.5723270440251573, "no_speech_prob": 0.05180864781141281}, {"id": 223, "seek": 307400, "start": 3075.0, "end": 3089.0, "text": " one thing I've tried to draw attention to in this talk is there's a risk with just focusing on the best method if you're not sure how good it is or how good it is for your specific question.", "tokens": [50414, 472, 551, 286, 600, 3031, 281, 2642, 3202, 281, 294, 341, 751, 307, 456, 311, 257, 3148, 365, 445, 8416, 322, 264, 1151, 3170, 498, 291, 434, 406, 988, 577, 665, 309, 307, 420, 577, 665, 309, 307, 337, 428, 2685, 1168, 13, 51114], "temperature": 0.0, "avg_logprob": -0.23231145168872588, "compression_ratio": 1.4728682170542635, "no_speech_prob": 0.2199261486530304}, {"id": 224, "seek": 308900, "start": 3089.0, "end": 3105.0, "text": " So what it's important, I think, to keep in mind that the best method is still a radical oversimplification of biology, whatever you do, however good it is, however much progress we make on multiple alignment over the next 10 years.", "tokens": [50364, 407, 437, 309, 311, 1021, 11, 286, 519, 11, 281, 1066, 294, 1575, 300, 264, 1151, 3170, 307, 920, 257, 12001, 15488, 332, 564, 3774, 295, 14956, 11, 2035, 291, 360, 11, 4461, 665, 309, 307, 11, 4461, 709, 4205, 321, 652, 322, 3866, 18515, 670, 264, 958, 1266, 924, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2557659842751243, "compression_ratio": 1.4320987654320987, "no_speech_prob": 0.07803302258253098}, {"id": 225, "seek": 310500, "start": 3106.0, "end": 3120.0, "text": " This will still be the case because the only way to really do it is just like simulate the entire planet for 3 billion years and see what evolution actually does. We can't do that. We make these very, very simplified computational models.", "tokens": [50414, 639, 486, 920, 312, 264, 1389, 570, 264, 787, 636, 281, 534, 360, 309, 307, 445, 411, 27817, 264, 2302, 5054, 337, 805, 5218, 924, 293, 536, 437, 9303, 767, 775, 13, 492, 393, 380, 360, 300, 13, 492, 652, 613, 588, 11, 588, 26335, 28270, 5245, 13, 51114], "temperature": 0.0, "avg_logprob": -0.23888146733663168, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.19651679694652557}, {"id": 226, "seek": 310500, "start": 3121.0, "end": 3128.0, "text": " And we should try to make them as good as possible. We should also try to have them interrogate themselves as to how good they are.", "tokens": [51164, 400, 321, 820, 853, 281, 652, 552, 382, 665, 382, 1944, 13, 492, 820, 611, 853, 281, 362, 552, 24871, 473, 2969, 382, 281, 577, 665, 436, 366, 13, 51514], "temperature": 0.0, "avg_logprob": -0.23888146733663168, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.19651679694652557}, {"id": 227, "seek": 312800, "start": 3129.0, "end": 3131.0, "text": " Okay, another question.", "tokens": [50414, 1033, 11, 1071, 1168, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2629141305622302, "compression_ratio": 1.2735042735042734, "no_speech_prob": 0.08266448229551315}, {"id": 228, "seek": 312800, "start": 3135.0, "end": 3142.0, "text": " So after generating the alignment, yes, it's possible to identify problematic regions.", "tokens": [50714, 407, 934, 17746, 264, 18515, 11, 2086, 11, 309, 311, 1944, 281, 5876, 19011, 10682, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2629141305622302, "compression_ratio": 1.2735042735042734, "no_speech_prob": 0.08266448229551315}, {"id": 229, "seek": 312800, "start": 3144.0, "end": 3146.0, "text": " And yes, you can refine those regions.", "tokens": [51164, 400, 2086, 11, 291, 393, 33906, 729, 10682, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2629141305622302, "compression_ratio": 1.2735042735042734, "no_speech_prob": 0.08266448229551315}, {"id": 230, "seek": 314600, "start": 3147.0, "end": 3149.0, "text": " And yes, you can refine those regions.", "tokens": [50414, 400, 2086, 11, 291, 393, 33906, 729, 10682, 13, 50514], "temperature": 0.0, "avg_logprob": -0.23834148530037172, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.09007547795772552}, {"id": 231, "seek": 314600, "start": 3150.0, "end": 3167.0, "text": " But some regions are simply not meaningful because there's no homology there or no sequence similarity there. So you may be better off identifying those regions. And muscle 5 does this. It assigns a column confidence score to every column.", "tokens": [50564, 583, 512, 10682, 366, 2935, 406, 10995, 570, 456, 311, 572, 3655, 1793, 456, 420, 572, 8310, 32194, 456, 13, 407, 291, 815, 312, 1101, 766, 16696, 729, 10682, 13, 400, 8679, 1025, 775, 341, 13, 467, 6269, 82, 257, 7738, 6687, 6175, 281, 633, 7738, 13, 51414], "temperature": 0.0, "avg_logprob": -0.23834148530037172, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.09007547795772552}, {"id": 232, "seek": 316700, "start": 3168.0, "end": 3193.0, "text": " And, of course, it depends why did you make the alignment and what inference do you make from it so it's always a bit risky to give general rules but as a general rule maybe you should just ignore those columns because it's not given that every column has to mean something, because you may remember I said, well, there are quite a few types of mutation that the alignment cannot represent.", "tokens": [50414, 400, 11, 295, 1164, 11, 309, 5946, 983, 630, 291, 652, 264, 18515, 293, 437, 38253, 360, 291, 652, 490, 309, 370, 309, 311, 1009, 257, 857, 21137, 281, 976, 2674, 4474, 457, 382, 257, 2674, 4978, 1310, 291, 820, 445, 11200, 729, 13766, 570, 309, 311, 406, 2212, 300, 633, 7738, 575, 281, 914, 746, 11, 570, 291, 815, 1604, 286, 848, 11, 731, 11, 456, 366, 1596, 257, 1326, 3467, 295, 27960, 300, 264, 18515, 2644, 2906, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2766750426519485, "compression_ratio": 1.6595744680851063, "no_speech_prob": 0.19676010310649872}, {"id": 233, "seek": 319300, "start": 3194.0, "end": 3206.0, "text": " So, if you go too far and try to force the alignment into some kind of shape, it may just not be meaningful because the mutations that happened, don't fit.", "tokens": [50414, 407, 11, 498, 291, 352, 886, 1400, 293, 853, 281, 3464, 264, 18515, 666, 512, 733, 295, 3909, 11, 309, 815, 445, 406, 312, 10995, 570, 264, 29243, 300, 2011, 11, 500, 380, 3318, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2725642419630481, "compression_ratio": 1.467065868263473, "no_speech_prob": 0.04270799458026886}, {"id": 234, "seek": 319300, "start": 3212.0, "end": 3220.0, "text": " Awesome. I think, let the chance question be the last question, it will be a nice ending.", "tokens": [51314, 10391, 13, 286, 519, 11, 718, 264, 2931, 1168, 312, 264, 1036, 1168, 11, 309, 486, 312, 257, 1481, 8121, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2725642419630481, "compression_ratio": 1.467065868263473, "no_speech_prob": 0.04270799458026886}, {"id": 235, "seek": 322000, "start": 3221.0, "end": 3225.0, "text": " So, okay, let me read the question for identifying what follows just genes.", "tokens": [50414, 407, 11, 1392, 11, 718, 385, 1401, 264, 1168, 337, 16696, 437, 10002, 445, 14424, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2849695828496193, "compression_ratio": 1.3533834586466165, "no_speech_prob": 0.05415768176317215}, {"id": 236, "seek": 322000, "start": 3232.0, "end": 3237.0, "text": " Okay, no, is my answer to that question. That was an easy one.", "tokens": [50964, 1033, 11, 572, 11, 307, 452, 1867, 281, 300, 1168, 13, 663, 390, 364, 1858, 472, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2849695828496193, "compression_ratio": 1.3533834586466165, "no_speech_prob": 0.05415768176317215}, {"id": 237, "seek": 322000, "start": 3241.0, "end": 3243.0, "text": " Would you like to elaborate a little bit.", "tokens": [51414, 6068, 291, 411, 281, 20945, 257, 707, 857, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2849695828496193, "compression_ratio": 1.3533834586466165, "no_speech_prob": 0.05415768176317215}, {"id": 238, "seek": 325000, "start": 3250.0, "end": 3261.0, "text": " Okay, I think that's about the end of our seminar and thank you so much, Robert, and everybody if you don't mind you can unmute yourself and give Dr. Robert a round of applause.", "tokens": [50364, 1033, 11, 286, 519, 300, 311, 466, 264, 917, 295, 527, 29235, 293, 1309, 291, 370, 709, 11, 7977, 11, 293, 2201, 498, 291, 500, 380, 1575, 291, 393, 41445, 1803, 293, 976, 2491, 13, 7977, 257, 3098, 295, 9969, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2736361167010139, "compression_ratio": 1.4855491329479769, "no_speech_prob": 0.024390101432800293}, {"id": 239, "seek": 325000, "start": 3262.0, "end": 3263.0, "text": " Okay, thank you very much.", "tokens": [50964, 1033, 11, 1309, 291, 588, 709, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2736361167010139, "compression_ratio": 1.4855491329479769, "no_speech_prob": 0.024390101432800293}, {"id": 240, "seek": 325000, "start": 3264.0, "end": 3267.0, "text": " Thank you. Please have a nice day. Bye bye everyone.", "tokens": [51064, 1044, 291, 13, 2555, 362, 257, 1481, 786, 13, 4621, 6543, 1518, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2736361167010139, "compression_ratio": 1.4855491329479769, "no_speech_prob": 0.024390101432800293}, {"id": 241, "seek": 328000, "start": 3280.0, "end": 3281.0, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50414], "temperature": 0.0, "avg_logprob": -0.5582656860351562, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9981192946434021}, {"id": 242, "seek": 331000, "start": 3310.0, "end": 3311.0, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50414], "temperature": 0.0, "avg_logprob": -0.5337596337000529, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9989338517189026}, {"id": 243, "seek": 334000, "start": 3340.0, "end": 3341.0, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50414], "temperature": 0.0, "avg_logprob": -0.4046562910079956, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9986016154289246}, {"id": 244, "seek": 337000, "start": 3370.0, "end": 3372.0, "text": " Thank you.", "tokens": [50414, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.33496705691019696, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9980619549751282}, {"id": 245, "seek": 340000, "start": 3400.0, "end": 3402.0, "text": " Thank you.", "tokens": [50414, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.31839489936828613, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9973701238632202}, {"id": 246, "seek": 343000, "start": 3430.0, "end": 3432.0, "text": " Thank you.", "tokens": [50414, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.31006181240081787, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9974321722984314}, {"id": 247, "seek": 346000, "start": 3460.0, "end": 3462.0, "text": " Thank you.", "tokens": [50414, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.3041742245356242, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9974289536476135}], "language": "en"}